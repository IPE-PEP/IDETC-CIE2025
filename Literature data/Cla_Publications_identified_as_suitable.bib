
@article{jiang_deriving_2021,
	title = {Deriving {Design} {Feature} {Vectors} for {Patent} {Images} {Using} {Convolutional} {Neural} {Networks}},
	volume = {143},
	issn = {1050-0472},
	doi = {10.1115/1.4049214},
	abstract = {The patent database is often used by designers to search for inspirational stimuli for innovative design opportunities because of the large size, extensive variety, and the massive quantity of design information contained in patent documents. Growing work on design-by-analogy has adopted various vectorization approaches for associating design documents. However, they only focused on text analysis and ignored visual information. Research in engineering design and cognitive psychology has shown that visual stimuli may benefit design ideation. In this study, we focus on visual design stimuli and automatically derive the vector space and the design feature vectors representing design images. The automatic vectorization approach uses a novel convolutional neural network architecture named Dual-Visual Geometry Group (VGG) aiming to accomplish two tasks: visual material-type prediction and international patent classification (IPC) section-label predictions. The derived feature vectors that embed both visual characteristics and technology-related knowledge can be potentially utilized to guide the retrieval and use of near-field and far-field design stimuli according to their vector distances. We report the accuracy of the training tasks and also use a case study to demonstrate the advantages of design image retrievals based on our model.},
	number = {6},
	journal = {JOURNAL OF MECHANICAL DESIGN},
	author = {Jiang, S and Luo, JX and Ruiz-Pava, G and Hu, J and Magee, CL},
	month = jun,
	year = {2021},
	keywords = {abstract ok, Artificial intelligence, Computer aided design, Computer-aided design, Convolution, Convolutional neural network, Convolutional neural networks, Data-driven design, Deep learning, Design automation, Design automations, Design by analogies, Design features, Design representation, Design-by-analogy, Features vector, Machine learning, Machine-learning, Network architecture, Patent image, Patent images, Patents and inventions, Vector spaces, Vectors},
}

@article{sun_product_2022,
	title = {Product {Classification} {With} the {Motivation} of {Target} {Consumers} by {Deep} {Learning}},
	volume = {10},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2022.3181624},
	abstract = {Due to the dynamic and competitive market environment, it is widely recognized that the development of new products and processes has become the critical point of attention for many companies. The first step in the product development process is to define the nature and function of the product, which is to classify the new product. The traditional product classification process only focuses on the product and market, which is developed by designers on the basis of the products of past dynasties. This way is labor-consuming, inefficient, and has become a bottleneck or constraint for these enterprises to improve their productivities and regulate production. In recent years, Artificial Intelligence has been applied in a wide range of fields including product classification. How to apply machine learning technologies to solve the classification problem of product classification has been widely concerned by researchers. In this paper, a fast and effective product classification, called MdmNet, is proposed, which is based on a novel attempt that embeds the innovation idea of human in machine learning technologies. MdmNet includes three modules: a target customer modeling method based on the deep learning technologies a consumer information deduction method based on the MDM that builds a consumer feature closed loop and output the classification result of the consumers' perspective, and a weighted fusion module. Experiments conducted on benchmark datasets Cars demonstrate the impressive performance of the proposed MdmNet. This paper first attempts to add consumer motivation analysis to traditional machine learning method, which has a strong application prospect.},
	journal = {IEEE ACCESS},
	author = {Sun, F and Luh, DB and Zhao, YL and Sun, Y},
	year = {2022},
	keywords = {Deep learning, Benchmarking, New product development, Product development, deep learning, Product design, Ergonomics, Motivation, Image recognition, product classification, Prototype, Design models, Classification (of information), Commerce, Features extraction, Machine learning technology, Dynamic market, motivation design model, Motivation design model, Product classification, abstract ok},
	pages = {62258--62267},
}

@inproceedings{akay_automating_2021,
	title = {{AUTOMATING} {DESIGN} {REQUIREMENT} {EXTRACTION} {FROM} {TEXT} {WITH} {DEEP} {LEARNING}},
	isbn = {978-0-7918-8539-0},
	abstract = {Nearly every artifact of the modern engineering design process is digitally recorded and stored, resulting in an overwhelming amount of raw data detailing past designs. Analyzing this design knowledge and extracting functional information from sets of digital documents is a difficult and time-consuming task for human designers. For the case of textual documentation, poorly written superfluous descriptions filled with jargon are especially challenging for junior designers with less domain expertise to read. If the task of reading documents to extract functional requirements could be automated, designers could actually benefit from the distillation of massive digital repositories of design documentation into valuable information that can inform engineering design. This paper presents a system for automating the extraction of structured functional requirements from textual design documents by applying state of the art Natural Language Processing (NLP) models. A recursive method utilizing Machine Learning-based question-answering is developed to process design texts by initially identifying the highest-level functional requirement, and subsequently extracting additional requirements contained in the text passage. The efficacy of this system is evaluated by comparing the Machine Learning-based results with a study of 75 human designers performing the same design document analysis task on technical texts from the field of Microelectromechanical Systems (MEMS). The prospect of deploying such a system on the sum of all digital engineering documents suggests a future where design failures are less likely to be repeated and past successes may be consistently used to forward innovation.},
	author = {Akay, H and Yang, M and Kim, SG and {AMER SOC MECHANICAL ENGINEERS}},
	year = {2021},
	keywords = {abstract ok, Computer aided design, Deep learning, Design automation, Design automations, Design documents, Design knowledge, Design representation, Distillation, Electromechanical devices, Engineering design process, Extraction, Functional reasoning, Functional requirement, Learning algorithms, Machine-learning, MEMS, Modern engineering, Natural language processing systems, Neural networks, Neural-networks, Product design, Product development},
}

@article{bodendorf_deep_2022,
	title = {Deep learning based cost estimation of circuit boards: a case study in the automotive industry},
	volume = {60},
	issn = {0020-7543},
	doi = {10.1080/00207543.2021.1998698},
	abstract = {Early cost estimation is a decisive value driver in the product development process in manufacturing industries. Machine learning offers new intelligent methods to support traditional cost calculation processes. While traditional research on intelligent cost estimation focuses on machine learning regression or classification models, we propose a new approach based on interlocking deep learning methods. In this paper we investigate the applicability of deep learning techniques, focusing on image recognition and deep learning regression as well as autoencoding to estimate product costs of circuit boards to be purchased. We create and evaluate deep learning models using real-world data from an original equipment manufacturer (OEM). Our findings suggest that deep learning models can streamline cost calculation and estimation processes while deep learning object recognition-based cost estimation outperforms autoencoding techniques. This research is designed to be transferable to other cost estimation projects.},
	number = {23},
	journal = {INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH},
	author = {Bodendorf, F and Merbele, S and Franke, J},
	month = dec,
	year = {2022},
	keywords = {abstract ok, autoencoding, Autoencoding, automotive industry, Automotive industry, Calculation process, Case-studies, Circuit boards, Cost benefit analysis, Cost calculation, Cost estimating, Cost estimation, Cost estimations, deep learning, Deep learning, Image recognition, Learning models, Learning systems, Machine-learning, Manufacture, object recognition, Object recognition, Objects recognition, Timing circuits},
	pages = {6945--6966},
}

@article{piotrowski_machine_2024,
	title = {Machine learning approach to packaging compatibility testing in the new product development process},
	volume = {35},
	issn = {0956-5515},
	doi = {10.1007/s10845-023-02090-8},
	abstract = {The paper compares the effectiveness of selected machine learning methods as modelling tools supporting the selection of a packaging type in new product development process. The main goal of the developed model is to reduce the risk of failure in compatibility tests which are preformed to ensure safety, durability, and efficacy of the finished product for the entire period of its shelf life and consumer use. This kind of testing is mandatory inter alia for all aerosol packaging as any mechanical alterations of the packaging can cause the pressurized product to unseal and stop working properly. Moreover, aerosol products are classified as dangerous goods and any leaking of the product or propellent can be a serious hazard to the storage place, environment, and final consumer. Thus, basic compatibility observations of metal aerosol packaging (i.e. general corrosion, pitting corrosion, coating blistering or detinning) and different compatibility factors (e.g. formula ingredients, water contamination, pH, package material and coatings) were discussed. Artificial intelligence methods applied in the design process can reduce the lengthy testing time as well as developing costs and help benefit from the knowledge and experience of technologists stored in historical data in databases.},
	number = {3},
	journal = {JOURNAL OF INTELLIGENT MANUFACTURING},
	author = {Piotrowski, N},
	month = mar,
	year = {2024},
	keywords = {abstract ok, Aerosols, Aluminum coatings, Aluminum corrosion, Atmospheric corrosion, Compatibility testing, Corrosion resistant coatings, Data visualization, Developed model, Digital storage, Durability, Machine learning, Machine learning approaches, Machine learning methods, Machine-learning, Modelling tools, New product development, New product development process, Packaging, Pitting, Smart products, Tool supporting, Water pollution, Well testing},
	pages = {963--975},
}

@article{du_new_2018,
	title = {A new data-driven design methodology for mechanical systems with high dimensional design variables},
	volume = {117},
	issn = {0965-9978},
	doi = {10.1016/j.advengsoft.2017.12.006},
	abstract = {Complicated engineering products such as cars with a large number of components can be regarded as big data systems, where the vast amount of dependent and independent design variables must be considered systematically during the product development. To design such a system with high-dimensional design variables, this study aims at developing a novel methodology based on data mining theory, and it is implemented through designing a crashworthy passenger car, which is a multi-level (system -components) complicated system. Decision tree technique was used to mine the crash simulation datasets to identify the key design variables with most significant effect on the vehicular energy absorption response and determine the range of their values. In this way, the design space can be significantly reduced and the high-dimensional design problem is greatly simplified. The results suggest that the data mining based approach can be used to design a complicated structure with multiple parameters effectively and efficiently. Compared with the traditional design method, the new approach could simplify and speed up the design process without significant influence on the accuracy.},
	journal = {ADVANCES IN ENGINEERING SOFTWARE},
	author = {Du, XP and Zhu, F},
	month = mar,
	year = {2018},
	keywords = {abstract ok, Accidents, Big data, Complicated structures, Crashworthiness, Critical parameters identification (CPI), Data mining, Decision tree techniques, Decision trees, Design domain reduction (DDR), Design domains, Energy absorption response, Engineering products, High-dimensional, High-dimensional design variables, Machine design, Number of components, Parameters identification, Product design, Structural design, Vehicle crashworthiness},
	pages = {18--28},
}

@article{qiu_document_2023,
	title = {Document {Understanding}-{Based} {Design} {Support}: {Application} of {Language} {Model} for {Design} {Knowledge} {Extraction}},
	volume = {145},
	issn = {1050-0472},
	doi = {10.1115/1.4063161},
	abstract = {Design knowledge in the vast amount of design reports and documents can be an excellent resource for designers in their practice. However, capturing such domain-specific information embedded in long-length unstructured texts is always time-consuming and sometimes tricky. Therefore, it is highly desirable for a computer system to automatically extract the main knowledge points and their corresponding inner structures from given documents. In this study of document understanding for design support (DocUDS), a design-perspective knowledge extraction approach is proposed that uses phrase-level domain-specific labeled datasets to finetune a Bidirectional Encoder Representation from Transformers (BERT) model so that it can extract design knowledge from documents. The BERT model finetuning attempts to blend in the domain-specific knowledge of well-recognized domain concepts and is based on the datasets generated from design reports. The model is utilized to map the captured sentences to the main design entities {\textless}reguirement{\textgreater}, {\textless}function{\textgreater}, and{\textless}solution{\textgreater}. In addition, this approach uncovers inner relationships among the sentences and constructs overall structures of documents to enhance understanding. The definitions of design perspectives, inter-perspective relations, and intra-perspective relations are introduced, which together capture the main design knowledge points and their relations and constitute an understanding of the design domain knowledge of a text. The case study results have demonstrated the proposed approach's effectiveness in understanding and extracting relevant design knowledge points.},
	number = {12},
	journal = {JOURNAL OF MECHANICAL DESIGN},
	author = {Qiu, YJ and Jin, Y},
	month = dec,
	year = {2023},
	keywords = {abstract ok, artificial intelligence, Classification (of information), Computational linguistics, Computer aided design, conceptual design, Conceptual design, Data mining, design automation, Design automations, Design knowledge, Design-perspective knowledge extraction, document understanding, Document understanding, Domain Knowledge, Extraction, Knowledge extraction, language model, Language model, Learning algorithms, Learning systems, machine learning, Machine-learning, Natural language processing systems, phraselevel dataset, Phraselevel dataset, sentence-design entity mapping, Sentence-design entity mapping, Structural design, text classification, Text classification, Text processing},
}

@article{kawakami_development_2020,
	title = {Development of {Artificial} {Intelligence} to {Classify} {Quality} of {Transmission} {Shift} {Control} {Using} {Deep} {Convolutional} {Neural} {Networks}},
	volume = {69},
	issn = {0018-9545},
	doi = {10.1109/TVT.2020.3032191},
	abstract = {Automatic transmissions are a core component of modern vehicles, and achieving good shift quality is critical to enhance the driving experience. In companies that manufacture transmissions, expert engineers take great care in calibrating parameters for controlling hydraulic pressure with the goal of achieving targeted shift quality. Because we need human experts to evaluate shift quality, it is hard to shorten the time taken to calibrate the systems controlling hydraulic pressure. In this paper, to reduce such development time, we propose a novel framework of a Classifier of Shift Quality; it applies the standard Supervised Deep Learning techniques (CSQ-SDL) to time-series measurement data. The framework consists of five procedures: measurement data collection, labeling by experts, data augmentation, data standardization, and the training of deep convolutional neural networks. Moreover, we also carry out driving experiments in which CSQ-SDL is used to assess the engagement of the lock-up clutch of a specific transmission model. By using raw time-series data measured by ordinary sensors in advance, and labels written later by an expert engineer looking at the raw data, we build binary classifiers and test their performance. It turns out that the accuracy of predicting expert's judgment is high; the area under the curve is 0.94. The result indicates that the proposed method is capable shortening product development times and thus meeting the demands of today's competitive automotive market.},
	number = {12},
	journal = {IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY},
	author = {Kawakami, T and Ide, T and Moriyama, E and Hoki, K and Muramatsu, M},
	month = dec,
	year = {2020},
	keywords = {abstract ok, Area under the curves, Automatic transmission, Automobile manufacture, Binary classifiers, Convolution, convolutional neural networks, Convolutional neural networks, Data standardization, deep learning, Deep learning, Deep neural networks, Driving experiences, Hydraulic fluids, Hydraulic pressure, Learning techniques, Quality control, Quality of Transmission, shift quality, Time series, time-series data classification, Vehicle transmissions},
	pages = {16168--16172},
}

@article{ozcan_social_2021,
	title = {Social media mining for ideation: {Identification} of sustainable solutions and opinions},
	volume = {107},
	issn = {0166-4972},
	doi = {10.1016/j.technovation.2021.102322},
	abstract = {The availability of social media-based data creates opportunities to obtain information about consumers, trends, companies and technologies using text mining techniques. However, the quality of the data is a significant concern for social media-based analyses. The aim of this study was to mine tweets (microblogs) to explore trends and retrieve ideas for various purposes such as product development, technology and sustainability-oriented considerations. The core methodological approach was to create a classification model to identify tweets that contained an idea. This classification model was used as a pre-processing step so the query results obtained from the application programming interface were cleared from the messages that contained the search terms used in the query but did not contain an idea. The results of this study demonstrate that our method based on text mining, and supervised or semi-supervised classification methods, can extract ideas from social media. The social media data mining process illustrated in our study can be utilised as a decision-making tool to detect innovative ideas or solutions about a product or service and summarise them into meaningful clusters. We believe that our findings are significant for the sustainability, tech mining and innovation management communities.},
	journal = {TECHNOVATION},
	author = {Ozcan, S and Suloglu, M and Sakar, CO and Chatufale, S},
	month = sep,
	year = {2021},
	keywords = {Decision making, Text mining, Decision-making, Crowdsourcing, Sustainability, Semi-supervised learning, Support vector machines, Social networking (online), Sustainable development, Innovation management, Classification models, Application programming interfaces (API), Sustainable solution, Methodological approach, Text mining techniques, Decision making tool, Semi-supervised classification method, Social media data minings, abstract ok},
}

@article{huo_machine_2022,
	title = {Machine learning and {CBR} integrated mechanical product design approach},
	volume = {52},
	issn = {1474-0346},
	doi = {10.1016/j.aei.2022.101611},
	abstract = {Many works based on case-based reasoning (CBR) and rule-based reasoning (RBR) have been done to obtain a product concept intelligently, but researches on automatic and intelligent methods for the detailed design process are still lacking. To achieve the intelligent design of the whole process for mechanical product development, an approach based on cases and knowledge is proposed. First, considering that the actual product cases sample is small, correlations among product features and relationships between product features and requirements are evaluated based on design knowledge. According to these correlations and relationships, a design problem is decomposed into multiple parallel small-scale sub-problems not only to increase data samples but reduce data dimensions. Moreover, a hybrid method that combined Hamming distance with Euclidean distance is generated to retrieve similar cases, which can address both numerical and encoding factors. In addition, K-NearestNeighbor (KNN) algorithm and Linear regression are adopted to adapt the classification and numeric parameters, respectively, so that the detailed design process can be achieved without fixed knowledge template. Finally, a tool design software is developed based on Visual studio 2015 to verify the practicability of the proposed method.},
	journal = {ADVANCED ENGINEERING INFORMATICS},
	author = {Huo, YL and Liu, JB and Xiong, J and Xiao, WJ and Zhao, JF},
	month = apr,
	year = {2022},
	keywords = {abstract ok, Based on case-based reasoning, Case adaptation, Case based reasoning, Casebased reasonings (CBR), Cutting tool, Cutting tools, Design approaches, Design-process, Detailed design, Experiential knowledge, Hamming distance, Intelligent design, Intelligent designs, Machine learning, Mechanical product designs, Nearest neighbor search, Numerical methods, Product design, Product feature},
}

@article{zhang_machine_2021,
	title = {Machine learning-based design features decision support tool via customers purchasing data analysis},
	volume = {29},
	issn = {1063-293X},
	doi = {10.1177/1063293X20963313},
	abstract = {Decision-making on design features such as specifications and components is an essential aspect of new product development. Customers product preferences and their variations provide the basis of design features decision. Big data of product sales are an emerging source for the obtaining of customers preferences on product features. In this work, a machine learning-based design features decision support tool is proposed through big sales data analysis. Customers preferred product features and their combinations are predicted based on the sales data. Physical feasibility of the product features combinations is considered for customers preference analysis. Cluster analysis method is proposed to identify common and alternative design of product features. Based on specification/component relationships, design features decisions of product components are carried out by grouping product component into noncritical, common, and alternative components. A case study on electric toy cars was included to illustrate the effectiveness of the proposed method.},
	number = {2},
	journal = {CONCURRENT ENGINEERING-RESEARCH AND APPLICATIONS},
	author = {Zhang, J and Chu, XP and Simeone, A and Gu, PH},
	month = jun,
	year = {2021},
	keywords = {machine learning, Machine learning, Decision making, New product development, Product development, product development, big data, Product design, Cluster analysis, Decision support systems, customer preference, design feature, Design features, Sales, Specifications, Information analysis, Turing machines, Alternative designs, Decision support tools, Basis of designs, Cluster analysis methods, Physical feasibility, Preference analysis, abstract ok},
	pages = {124--141},
}

@inproceedings{wang_bridging_2017,
	title = {{BRIDGING} {THE} {SEMANTIC} {GAP} {IN} {CUSTOMER} {NEEDS} {ELICITATION}: {A} {MACHINE} {LEARNING} {PERSPECTIVE}},
	isbn = {2220-4334},
	abstract = {The elicitation of customer needs (CNs) is a critical step in product development. However, these needs are often expressed in ambiguous, simple language and not in the form of well-defined specifications, causing a semantic gap in the product development process. Traditional methods to bridge the gap rely heavily on human action. Product development teams need to manually link CNs to product specifications in an ad hoc manner. This may be infeasible for large product variant spaces or evolving product families. We propose a machine learning mechanism to automatically bridge the semantic gap. This task is considered as a classification problem, with CNs being the class. The mapping function from product specifications to CNs is learned from training data by using a support vector machine and decision tree classifier. Given a new product variant, the learnt classifier can determine the needs that the product variant can satisfy. Numerical experiments show that the proposed method can achieve very high mapping accuracy. It can also shield product development teams from the tedious labour of linking CNs to product variants, and thus improve the efficiency of needs elicitation.},
	author = {Wang, Y and Zhang, J},
	editor = {Maier, A and Skec, S and Kim, H and Kokkolaras, M and Oehmen, J and Fadel, G and Salustri, F and VanDerLoos, M},
	year = {2017},
	keywords = {Artificial intelligence, Decision making, Product development, Configurator, Semantics, Product development process, Decision trees, Mapping, Informatics, Requirements, Design informatics, Numerical methods, Specifications, Learning systems, Classification (of information), Trees (mathematics), Semantic gap, Product development teams, Decision tree classifiers, Machine learning mechanism, abstract ok},
	pages = {643--651},
}

@article{gozuacik_social_2021,
	title = {Social media-based opinion retrieval for product analysis using multi-task deep neural networks},
	volume = {183},
	issn = {0957-4174},
	doi = {10.1016/j.eswa.2021.115388},
	abstract = {Social media platforms are considered one of the most effective intermediaries for companies to interact with consumers. Social media-based decision support systems for the marketing domain are highly developed, but product development and innovation-oriented studies remain limited. This study offers a novel approach which utilises opinion retrieval theme along with sentiment analysis to support the decision-making process for product analysis and development. To achieve this aim, we propose an end-to-end social media-based opinion retrieval system and utilise machine learning and natural language processing techniques. Google Glass is chosen as a usecase as this product was unable to achieve its commercial targets despite its superior technological offerings. We design a multi-task deep neural network architecture for the training of sentiment prediction and opinion detection tasks. We first divide the tweets containing certain useful opinions and suggestions into two categories based on their sentiment labels. The negative tweets are analysed to identify product-related concerns, whereas the positive and neutral tweets are used to extract innovative ideas and identify new use cases for product development. We visualise and interpret the clusters of keywords extracted from each sentiment label group. Apart from methodological contributions, this study offers practical contributions for the next generations of smart glasses.},
	journal = {EXPERT SYSTEMS WITH APPLICATIONS},
	author = {Gozuacik, N and Sakar, CO and Ozcan, S},
	month = nov,
	year = {2021},
	keywords = {Deep learning, Decision making, Product development, Opinion mining, Natural language processing, Sentiment analysis, Text analytics, Social media, Decision support systems, Social networking (online), Feedback retrieval, Deep neural networks, Network architecture, Glass, Language processing, Natural languages, Opinion retrievals, Product analysis, abstract ok},
}

@inproceedings{spruegel_generic_2017,
	title = {{GENERIC} {APPROACH} {TO} {PLAUSIBILITY} {CHECKS} {FOR} {STRUCTURAL} {MECHANICS} {WITH} {DEEP} {LEARNING}},
	isbn = {2220-4334},
	abstract = {The simulation of product behavior is a vital part in virtual product development, but currently there is no tool or method available that can examine the quality of FE simulations and decide automatically on whether a simulation is plausible or non-plausible. In the paper a method is presented that enables automatic plausibility checks on basis of empirical simulation datasets. Nodal simulation data is transformed to numerical arrays, of fixed size, using virtual spherical detector surfaces. Afterwards the arrays are used to train a Deep Convolutional Neural Network (AlexNet). The Neural Network can then be used for plausibility checks of FE simulations (structural mechanics). In a first application a Deep Convolutional Neural Network is trained with simulation data of a demonstrator part, the rail of speed inline skates. After the GPU training of the Neural Network, further simulations are evaluated with the net. These simulations were not part of the training data and are used to calculate the prediction quality of the Neural Network. This approach is to support development engineers during design accompanying FEA in virtual product development.},
	author = {Spruegel, T and Schröppel, T and Wartzack, S},
	editor = {Maier, A and Skec, S and Kim, H and Kokkolaras, M and Oehmen, J and Fadel, G and Salustri, F and VanDerLoos, M},
	year = {2017},
	keywords = {abstract ok},
	pages = {299--308},
}

@article{choy_design_2004,
	title = {Design of an intelligent supplier relationship management system for new product development},
	volume = {17},
	issn = {0951-192X},
	doi = {10.1080/0951192042000237483},
	abstract = {Since the 1990s, the business environment has changed greatly because of global integration and the lifecycles of products are becoming shorter. The drive to continually cut costs and focus on core competencies has driven many to outsource some or all of their production. It is found that the integration of customer relationship management (CRM) and supplier relationship management (SRM), to facilitate supply chain management in the areas of supplier selection using an artificial intelligence approach, has become a promising solution for manufacturers to identify appropriate suppliers and trading partners to form a supply network on which they depend for products, services and distribution. In this paper, an intelligent supplier relationship management system (ISRMS) using hybrid case based reasoning (CBR) and artificial neural networks (ANNs) techniques to select and benchmark potential suppliers is discussed. By using ISRMS in Honeywell Consumer Product ( Hong Kong) Limited, the outsource cycle time from searching for potential suppliers to the allocation of order during new product development is greatly reduced.},
	number = {8},
	journal = {INTERNATIONAL JOURNAL OF COMPUTER INTEGRATED MANUFACTURING},
	author = {Choy, KL and Lee, WB and Lau, HCW and Lu, DW and Lo, V},
	month = dec,
	year = {2004},
	keywords = {abstract ok, Algorithms, Artificial neural networks (ANN), Consumer products, Customer relationship management (CRM), Customer satisfaction, Information retrieval, Intelligent agents, Management, Marketing, Multi agent systems, Neural networks, Parameter estimation, Supplier relationship management (SRM), Supply management},
	pages = {692--715},
}

@article{cok_methodology_2022,
	title = {Methodology for mapping form design elements with user preferences using {Kansei} engineering and {VDI}},
	volume = {33},
	issn = {0954-4828},
	doi = {10.1080/09544828.2021.2012133},
	abstract = {In product development, decisions about the appearance of the product are risky and difficult to make. Engineers and designers are aware that adding new design features or form design elements can degrade the visual appearance. Therefore, it is important to understand how future users perceive different design configurations. In this paper, an adapted Kansei Engineering (KE) methodology focusing on the extraction of affective attributes in product design is presented. The methodology is demonstrated using a case study in which we investigated the influence of e-bike form design elements on user perception. The study was conducted using 15 pairwise adjectives to describe feelings and a set of collected e-bike image samples with different product designs, converted to silhouettes. In addition to methodological refinement, a space of properties, specifically form design elements were categorised based on VDI 2223 guidelines. Semantic space was defined using predefined affective attributes and later reduced using factor analysis, while e-bike image similarity was exploited using the Agglomerative Hierarchical Clustering (AHC) method. Influential form design elements were extracted using the decision tree method for classification based on a C4.5 algorithm. Using this methodology, we succeeded in discovering key form design elements that determine user perception.},
	number = {2},
	journal = {JOURNAL OF ENGINEERING DESIGN},
	author = {Cok, V and Vlah, D and Povh, J},
	month = feb,
	year = {2022},
	keywords = {abstract ok, Bicycles, data mining, Data mining, Decision trees, Design elements, Design features, Design forms, Features design, Form design, Kansei engineering, Kansei Engineering, Product design, product development, Product development, Semantics, User perceptions, User's preferences, VDI 2223, Visual appearance},
	pages = {144--170},
}

@article{spruegel_approach_2021,
	title = {Approach and application to transfer heterogeneous simulation data from finite element analysis to neural networks},
	volume = {8},
	issn = {2288-5048},
	doi = {10.1093/jcde/qwaa079},
	abstract = {The simulation of product behavior is a vital part of current virtual product development. It can be expected that soon there will be more product simulations due to the availability of easy-to-use finite element analysis software and computational power. Consequently, the amount of accessible new simulation data adds up to the already existing amount. However, even when using easy-to-use finite element software tools, errors can occur during the setup of finite element simulations, and users should be warned about certain mistakes by automatic algorithms. To use the vast amount of available finite element simulations for a data-driven finite element support tool, in this paper, a methodology will be presented to transform different finite element simulations to unified matrices. The procedure is based on the projection of nodes onto a detector sphere, which is converted into a matrix in the next step. The generated matrices represent the simulation and can be described as the DNA of a finite element simulation. They can be used as an input for any machine learning model, such as convolutional neural networks. The essential steps of preprocessing the data and an application with a large dataset are part of this contribution. The trained network can then be used for an automatic plausibility check for new simulations, based on the previous simulation data from the past. This can result in a tool for automatic plausibility checks and can be the backbone for a feedback system for less experienced users.},
	number = {1},
	journal = {JOURNAL OF COMPUTATIONAL DESIGN AND ENGINEERING},
	author = {Spruegel, TC and Bickel, S and Schleich, B and Wartzack, S},
	month = feb,
	year = {2021},
	keywords = {abstract ok, artificial neural network, Automatic algorithms, Bioinformatics, Computational power, Computer aided software engineering, convolutional neural network, Convolutional neural networks, Data communication systems, deep neural network, Finite element analysis software, finite element method, Finite element method, finite element simulation, Finite element simulations, Finite element software, heterogeneity, Heterogeneous simulation, Large dataset, Machine learning models, Matrix algebra, numerical method, plausibility check, research work, simulation DNA, spherical detector surface, Virtual product development},
	pages = {298--315},
}

@inproceedings{wang_addressing_2021,
	title = {Addressing the {Semantic} {Gap} in the {Consumer}-to-{Manufacturer} {Strategy} {Using} {Dual} {Convolutional} {Neural} {Network}},
	isbn = {2157-3611},
	doi = {10.1109/IEEM50564.2021.9673094},
	abstract = {Customer-to-manufacturer (C2M) is an emerging smart manufacturing strategy. In C2M, customers are directly connected with manufacturers for tailor-made product development and manufacturing. Thus, the R\&D and marketing-driven process in traditional manufacturing evolves into a customer-driven product development process. Product sales using the C2M mode have been one of the highest growth sectors in Chinese ecommerce platforms. However, customers usually lack the necessary domain knowledge. They cannot communicate directly with engineers by indicating the desired technical specifications of the product. A semantic gap exists. This paper presents a dual convolutional neural network- (CNN) -based structure, to automatically address this semantic gap. To mitigate the data sparsity issue in the customer needs domain, we use a massive amount of product review texts which were crawled from ecommerce websites to build a source mapping from reviews to product technical specifications. A small amount of customer needs text was deployed to adapt the source mapping to the target customer needs-product specifications mapping and thus close the semantic gap. Promising experiment results were obtained to show the effectiveness of the method.},
	author = {Wang, Y and Li, X and {IEEE}},
	year = {2021},
	keywords = {Deep learning, Product development, Natural language processing, Semantics, Convolutional neural network, Mapping, Smart manufacturing, Electronic commerce, Manufacturing strategy, Advanced manufacturing, Convolutional neural networks, Manufacture, Sales, Specifications, Convolution, Natural language processing systems, Domain Knowledge, Semantic gap, Customer need, Technical specifications, Consumer-to-manufacturer, Tailor-made products, abstract ok},
	pages = {624--628},
}

@article{zhang_view-based_2019,
	title = {A view-based {3D} {CAD} model reuse framework enabling product lifecycle reuse},
	volume = {127},
	issn = {0965-9978},
	doi = {10.1016/j.advengsoft.2018.09.001},
	abstract = {3D CAD models have great significances for product lifecycle reuse as each model aggregates abundant knowledge in a vivid 3D CAD model and enables engineers to reuse the existing mature designs from a high-level perspective. The effective reuse of the pre-existing 3D CAD models could greatly save time and cost in new product development. Consequently, this paper proposes a novel view-based 3D CAD model reuse framework, which supports the effective reuse of 3D CAD models throughout the new product lifecycle by a deep learning approach. In this framework, each 3D CAD model is first represented by a series of orthogonal two-dimensional views, which contain rich spatial information for differentiating 3D CAD models. Then, we define the problem of model retrieval as a view recognition problem, where a deep residual network (ResNet) is successfully trained to facilitate the view-based 3D CAD model retrieval. With the learned ResNet, engineers could take the understandable views of a model that represent their query intents as input and acquire the relevant 3D CAD models for product lifecycle reuse. Finally, the typical application scenario demonstrates the feasibility of the proposed framework, and the evaluation experiments show the superiorities of ResNet used in this framework.},
	journal = {ADVANCES IN ENGINEERING SOFTWARE},
	author = {Zhang, C and Zhou, GH},
	month = jan,
	year = {2019},
	keywords = {abstract ok, Computer aided design, Deep learning, Evaluation experiments, Learning approach, Life cycle, Model aggregate, Model retrieval, New product development, Product development, Product lifecycle reuse, Product-life-cycle, Residual network, Spatial informations, Typical application, View-based approach},
	pages = {82--89},
}

@inproceedings{la_identifying_2019,
	title = {Identifying {Mode} {Shapes} of {Turbo}-{Machinery} {Blades} {Using} {Principal} {Component} {Analysis} and {Support} {Vector} {Machines}},
	isbn = {2191-5644},
	doi = {10.1007/978-3-319-74476-6_3},
	abstract = {Manually identifying mode shapes generated from finite element solvers images is an expensive task. This paper proposes an automated process to identify mode shapes from gray-scale images of compressor blades within a jet-engine. This work introduces mode shape identification using principal component analysis (PCA), similar to approaches in facial and other recognition tasks in computer vision. This technique calculates the projected values of potentially linearly correlated values onto P-linearly orthogonal axes, where P is the number of principal axes that define a subset space. Classification was done using support vector machines (SVM). Using the PCA and SVM algorithm, approximately 5300 training images representative of 16 different modes were used to create a classifier. The classifier achieved on average 98\% accuracy when tested using a test set of approximately 2000 images given P = 70. The results suggest that using digital images to perform mode shape identification can be achieved with high accuracy. Potential generalization of this method could be applied to other engineering design and analysis applications.},
	author = {La, A and Salmon, J and Ellingson, J},
	editor = {Niezrecki, C and Baqersad, J},
	year = {2019},
	keywords = {abstract ok, Automated process, Automation, Classification (of information), Compressor blades, Computer vision, Engineering design, Finite element solver, Gray-scale images, Image processing, Learning systems, Machine learning, Machinery, Mode shape identification, Mode shapes, Orthogonal axes, PCA, Principal axes, Structural analysis, Structural dynamics, Structural health monitoring, Support vector machines},
	pages = {23--26},
}

@article{liao_mining_2009,
	title = {Mining information users' knowledge for one-to-one marketing on information appliance},
	volume = {36},
	issn = {0957-4174},
	doi = {10.1016/j.eswa.2008.06.020},
	abstract = {All kinds of information technologies have been converging rapidly in recent few years from simple traditional computers to diversified multimedia information appliances, creating unprecedented technologies and devices, such as personal digital assistants (PDAs), smart cell phones, portable media players (PMPs), online console games, and set top boxes, among others. These electronic functionalities converged devices with powerful contents and functions, such as the World Wide Web, videoconferencing, e-mail, internet telephony, online gaming, digital television, and net banking, are easier to use than traditional computers but not less capable of performing daily tasks. These information technology revolutions along with rapid growing of network technology not only increased the amount of internet applications and digital contents, but also led to diversified consumer behaviors, increased competition, and opportunities. On the other hand, one-to-one marketing is different from traditional marketing methods because it focuses on customer satisfaction and is customer-oriented rather than focusing on marketing mass consumers; thus a one-to-one marketer tries to find more different products and services for the same customer. Therefore, how to establish potential cross-selling and one-to-one offers through product mix analysis, enhance relationship with customers by means of personalized offers through product knowledge, and understand users' needs and making useful suggestions for new product developments and one-to-one marketing become critical issues to information appliance firms. This paper proposes association rules, clustering analysis and CART as methodologies of data-mining, which is implemented for mining product and marketing knowledge from information users. Knowledge extraction from information users is illustrated as knowledge patterns, rules, clusters, and trees in order to propose suggestions on one-to-one marketing for information appliance firms. (C) 2008 Elsevier Ltd. All rights reserved.},
	number = {3},
	journal = {EXPERT SYSTEMS WITH APPLICATIONS},
	author = {Liao, SH and Chen, CM and Hsieh, CL and Hsiao, SC},
	month = apr,
	year = {2009},
	keywords = {Data mining, Ontology, Customer satisfaction, Clustering analysis, Data-mining, Knowledge extraction, Association rules, Information appliance, One-to-one marketing, Classification and regression tree, Consumer behavior, Sales, Classification (of information), Trees (mathematics), Extraction, Commerce, Computer games, Cellular telephone systems, Information use, Digital devices, Electronic mail, Classification and regression trees (CART), Digital television, Information appliances, Mobile phones, Personal digital assistants, Set-top boxes, Video conferencing, abstract ok},
	pages = {4967--4979},
}

@article{fang_machine_2024,
	title = {A machine learning and clustering-based methodology for the identification of lead users and their needs from online communities},
	volume = {248},
	issn = {09574174 (ISSN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184838263&doi=10.1016%2fj.eswa.2024.123381&partnerID=40&md5=c981bb84024b6aa07d171b8a2241aa91},
	doi = {10.1016/j.eswa.2024.123381},
	abstract = {Nowadays, online community platforms provide firms with an important source of information for conducting dynamic marketing research. High-technology companies, in particular, rely heavily on lead users for the development of very novel products or easily adjustable services. In this paper, we present a three-phase methodology that integrates a machine-learning-based algorithm with a sophisticated clustering technique. The purpose of this methodology is to systematically identify lead users and their needs from a complex online community network. We also aim to identify important features, perceptions, and preferences for different groups of lead users. To validate the effectiveness of our approach, we conduct a real-world case study. © 2024 Elsevier Ltd},
	language = {English},
	journal = {Expert Systems with Applications},
	author = {Fang, X. and Zhou, J. and Pantelous, A.A. and Lu, W.},
	year = {2024},
	note = {Publisher: Elsevier Ltd},
	keywords = {Clustering algorithms, New product development, Product development, Cluster analysis, Social networking (online), Marketing, Machine-learning, Random forests, Online community, Learning algorithms, Clusterings, Online systems, On-line communities, Sources of informations, Clustering technique, Clustering techniques, Lead users, Marketing research, Random forest-based algorithm, abstract ok},
}

@article{shahin_adapting_2024,
	title = {Adapting the {GPT} engine for proactive customer insight extraction in product development},
	volume = {41},
	issn = {22138463 (ISSN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206272071&doi=10.1016%2fj.mfglet.2024.09.164&partnerID=40&md5=844bf6947f0835e8846445d302900bcd},
	doi = {10.1016/j.mfglet.2024.09.164},
	abstract = {Understanding the perceptions of consumers is widely recognized as a critical element in the innovation of new products. Traditional techniques used by companies to collect essential consumer insights have largely remained unchanged. Common practices like interviews and surveys have distinct limitations. Interviews may not always capture the precise needs of consumers due to communication barriers, and surveys tend to encourage incremental changes rather than radical innovations. Service industries face further complexity as they navigate customer feedback on the more intangible aspects of service quality. This study highlights the pioneering use of GPT-3.5 Turbo, a tool known for its exceptional ability to delve into the nuances of conversational context and process data in a chat-centric manner, thereby enhancing the extraction of Voice of the Customer (VoC). Its capability to handle large volumes of data in multiple languages leads to a more thorough and inclusive VoC analysis. The study links these technological advancements with Lean Six Sigma 4.0, suggesting that incorporating GPT-3.5 Turbo could significantly improve the customer-focused strategies in the current industrial landscape. This breakthrough in VoC analysis suggests possibilities for more perceptive, immediate data-driven approaches in customer service, and lays a stronger groundwork for decisions in product evolution and process enhancement. The paper concludes by urging further investigation to confirm these initial results and to explore the ethical aspects of employing such advanced natural language processing technologies. © 2024 The Author(s)},
	language = {English},
	journal = {Manufacturing Letters},
	author = {Shahin, M. and Chen, F.F. and Maghanaki, M. and Hosseinzadeh, A.},
	year = {2024},
	note = {Publisher: Elsevier Ltd},
	keywords = {Artificial Intelligence, Six sigma, Industry 5.0, Voice of the customer, Lean Six Sigma, Sales, Natural language processing systems, Traditional techniques, Data handling, ChatGPT, Ethical technology, Communication barriers, Consumer insights, Critical elements, Customer analysis, Customer insights, VoC, abstract ok},
	pages = {1376--1385},
}

@article{choudhury_can_2024,
	title = {Can machine learning approaches predict green purchase intention? -{A} study from {Indian} consumer perspective},
	volume = {456},
	issn = {09596526 (ISSN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191982413&doi=10.1016%2fj.jclepro.2024.142218&partnerID=40&md5=15ab4d30736ae78df21afc23490bfd0a},
	doi = {10.1016/j.jclepro.2024.142218},
	abstract = {This paper explores consumer green consumption practices and considers a set of factors, including cognitive and behavioural level constructs, that influence green consumption. The paper primarily aims to predict the green purchase intention and classify a consumer as a green or non-green consumer. A total of 310 responses were collected and analyzed using machine Learning techniques like Decision Tree, Random Forest, Gradient Boosting, XGBoost, K-Nearest Neighbour, and Support Vector Machine, and the models were validated using different performance metrics. The paper reveals that the main driving factors for a consumer to consider greener options are green self-identification, followed by environmental knowledge, environmental consciousness, and the impact of social media. The current work will allow better product development and the targeting and positioning of green products/services offerings to customers already classified by the system. © 2024 The Authors},
	language = {English},
	journal = {Journal of Cleaner Production},
	author = {Choudhury, N. and Mukherjee, R. and Yadav, R. and Liu, Y. and Wang, W.},
	year = {2024},
	note = {Publisher: Elsevier Ltd},
	keywords = {Machine learning, Support vector machines, Decision trees, Machine-learning, Purchasing, Sales, Feature importance, Purchase intention, Learning systems, Machine learning approaches, Nearest neighbor search, Adaptive boosting, Behavioral level, Cognitive levels, Environmental knowledge, Green consumption, Green purchase intention, Self-green identification, abstract ok},
}

@article{xu_tolerance_2024,
	title = {Tolerance {Information} {Extraction} for {Mechanical} {Engineering} {Drawings} – {A} {Digital} {Image} {Processing} and {Deep} {Learning}-based {Model}},
	volume = {50},
	issn = {17555817 (ISSN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186111848&doi=10.1016%2fj.cirpj.2024.01.013&partnerID=40&md5=4eddcad46a62d431ff58aed6dd98cb92},
	doi = {10.1016/j.cirpj.2024.01.013},
	abstract = {Mechanical engineering drawings (MEDs) accompany a product lifecycle from conceptional design to final production. The digitisation of MEDs has become increasingly important due to demands for data authenticity, intellectual property protection, efficient data storage and communication, and compliance with data integrity and security regulations. Unlike CAD-based engineering design software, legacy MEDs are often manually drawn or contain manually labeled specifications on blueprints. A notable gap exists in the automated process pipeline of modern Computer-Aided Tolerance (CAT) software, particularly in integrating Geometrical Tolerance Specification Callouts (GTSC) on MEDs. This study proposes an integrated model based on digital image processing and deep learning, which combines character (symbol, text and number) localization, segmentation, and recognition to intelligently identify and read GTSCs on MEDs. The focus of this work is on image filtering, GTSC block localization and tilt correction, multiple lines and character segmentation, and semantic recognition. Experiment results demonstrate that this innovative technique effectively automates the labor-intensive process of reading and registering GTSC with a precision performance that meets industry benchmarks. © 2024 Elsevier Ltd},
	language = {English},
	journal = {CIRP Journal of Manufacturing Science and Technology},
	author = {Xu, Y. and Zhang, C. and Xu, Z. and Kong, C. and Tang, D. and Deng, X. and Li, T. and Jin, J.},
	year = {2024},
	note = {Publisher: Elsevier Ltd},
	keywords = {abstract ok, Automation, Benchmarking, Callouts, Character extraction, Character recognition, Computer aided design, Deep learning, Digital storage, Digitalization, E-learning, Engineering drawing, Geometrical tolerance specification callout, Geometrical tolerance specification callout block, Geometrical tolerance specification callouts, Geometrical tolerances, GTSC blocks, Life cycle, Mechanical engineering drawing, Mechanical engineering drawings, Product design, Semantic Segmentation, Semantics, Specifications, Tolerance specifications},
	pages = {55--64},
}

@article{shahin_novel_2024,
	title = {A novel approach to voice of customer extraction using {GPT}-3.5 {Turbo}: linking advanced {NLP} and {Lean} {Six} {Sigma} 4.0},
	volume = {131},
	issn = {02683768 (ISSN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185264239&doi=10.1007%2fs00170-024-13167-w&partnerID=40&md5=8fe544ca0db16e41303598aee32bd34b},
	doi = {10.1007/s00170-024-13167-w},
	abstract = {This research breaks new ground by utilizing the advanced natural language processing (NLP) capabilities of OpenAI’s GPT-3.5 Turbo model for the extraction of voice of customer (VoC) data from online customer support interactions on Twitter. Traditional methods of VoC extraction have typically fallen short in capturing the richness and nuance of customer sentiment. Contemporary machine learning (ML) approaches, while improved, still struggle to interpret the contextual subtleties of digital customer communications effectively. This study showcases the innovative deployment of GPT-3.5 Turbo, demonstrating its superior performance in extracting VoC through a deeper understanding of conversational context and a more intuitive, chat-based data processing. Furthermore, the large-scale, multilingual processing capabilities of this model offer a more comprehensive and inclusive analysis of VoC. The study ties these advancements to Lean Six Sigma 4.0, illustrating how the integration of GPT-3.5 Turbo’s transformative capabilities can elevate the customer-centric approach of Lean Six Sigma in the era of Industry 4.0. This innovative exploration points to a significant evolution in VoC analysis, offering potential for more insightful, real-time data–driven customer service strategies and a more substantial foundation for decision-making in product development and process improvement. Future research is encouraged to validate these preliminary findings and to investigate ethical considerations associated with the use of such advanced NLP models. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.},
	language = {English},
	number = {7-8},
	journal = {International Journal of Advanced Manufacturing Technology},
	author = {Shahin, M. and Chen, F.F. and Hosseinzadeh, A. and Maghanaki, M. and Eghbalian, A.},
	year = {2024},
	note = {Publisher: Springer Science and Business Media Deutschland GmbH},
	keywords = {Industry 4.0, Data mining, Decision making, Process monitoring, Six sigma, Text analysis, Lean Six Sigma, Lean production, Sales, Text-mining, Mathematical transformations, Extraction, Natural language processing systems, Data handling, Language model, Large language model, Language processing, Natural languages, ChatGPT, VoC, Processing capability, Text mining and analysis, Voices of customers, Work simplification, abstract ok},
	pages = {3615--3630},
}

@article{kim_identifying_2024,
	title = {Identifying {Promising} {Technologies} {Considering} {Technology} {Convergence}: {A} {Patent}-{Based} {Machine}-{Learning} {Approach}},
	volume = {71},
	issn = {00189391 (ISSN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206875601&doi=10.1109%2fTEM.2024.3477508&partnerID=40&md5=740ae1f48bdd86cfe6e4b2e94798bb99},
	doi = {10.1109/TEM.2024.3477508},
	abstract = {With drastic changes in technology and its converging power in new product development, technology convergence has long been considered imperative in the innovation literature. Despite these efforts, previous articles neglected the importance of technology convergence in identifying promising technologies. To address this limitation, this article assumes that patents with high mediating power for subsequent technology convergence are likely to be promising. For this purpose, this article proposes the concept of convergence distance, which is measured by the differences in IPCs in backward and forward citations of patents, and defines it as the mediating power of technology convergence. Three indicators are defined: convergence distance, convergence intensity, and convergence diversity. Using these convergence-related indicators, we developed a machine-learning model to predict promising technologies. Consequently, the models with new evolution indicators outperformed the original models. Moreover, our suggested indicators turned out to be very important for predicting promising technologies, implying that the mediating power of technology convergence is very important for predicting future promising technologies and should be considered very significant for technology opportunity discovery.  © 1988-2012 IEEE.},
	language = {English},
	journal = {IEEE Transactions on Engineering Management},
	author = {Kim, J. and Geum, Y.},
	year = {2024},
	note = {Publisher: Institute of Electrical and Electronics Engineers Inc.},
	keywords = {machine learning, New product development, Patent analysis, Machine-learning, Machine learning models, patent analysis, Machine learning approaches, Power, Convergence distance, Development technology, promising technology, Promising technology, technology convergence, Technology convergence, abstract ok},
	pages = {15096--15109},
}

@article{li_promoting_2024,
	title = {Promoting knowledge recommendation in innovative engineering design: a {BERT}-{GAT}-based patent representation learning approach},
	issn = {09544828 (ISSN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191770315&doi=10.1080%2f09544828.2024.2339713&partnerID=40&md5=dd93c262a1766d8d6b7136e6724a82d5},
	doi = {10.1080/09544828.2024.2339713},
	abstract = {Since innovation in complex product design hinges on thorough engineering knowledge application, high-quality patent recommendations foster innovation in engineering design. However, many patent knowledge recommendation studies perform patent analysis without comprehensive exploration and proper organisation of knowledge, causing a superficial understanding of patents and returning arbitrary results. To mitigate this issue, a deep learning-based approach for patent representation learning and knowledge recommendation is proposed. First, a four-dimensional patent knowledge model is defined to formalise the patent attributes that critically affect the engineering design outcomes, namely patents’ domain(D), function(F), technology(T) and citation(C). Second, to exploit patent knowledge from their content and citation relationships, a representation learning approach integrating Bidirectional Encoder Representations from Transformers(BERT) and Graph Attention Network(GAT) is introduced. Thereafter a patent knowledge space is established in which each patent is characterised by the function, technology, and citation embeddings. Third, a knowledge requirement space is also constructed by vectorising a designer’s search query via BERT model and linking it to a requirement-representing patent based on similarity. Finally, a recommender prototype is developed and showcased by the knowledge recommendation in sealing structure design tasks. Comparative experiments and application cases validate the effectiveness of our method in patent representation learning and knowledge recommendation. © 2024 Informa UK Limited, trading as Taylor \& Francis Group.},
	language = {English},
	journal = {Journal of Engineering Design},
	author = {Li, M. and Wang, Z. and Yan, Z. and Liang, X. and Liu, J.},
	year = {2024},
	note = {Publisher: Taylor and Francis Ltd.},
	keywords = {abstract ok, BERT, Bidirectional encoder representation from transformer, Complex products, Deep learning, Engineering design, Engineering education, GAT, Graph attention network, Innovative engineering, Innovative engineering design, knowledge recommendation, Knowledge recommendation, Learning approach, Network-based, patent representation learning, Patent representation learning, Patents and inventions, Product design, Query processing, Recommender systems, Search engines},
}

@article{febiula_machine_2024,
	title = {Machine {Learning}-driven {Marketing} {Strategies} in the {Mobile} {Gadget} {Industry} for {Enhancing} {Customer} {Engagement} and {Sales} {Optimization}},
	volume = {20},
	issn = {16606795 (ISSN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201644931&doi=10.62441%2fnano-ntp.v20iS7.5&partnerID=40&md5=cd7ad8c89ab0b21b133abfa905a4c237},
	doi = {10.62441/nano-ntp.v20iS7.5},
	abstract = {The objective of the research consists of transforming the face of product development and marketing strategies within the mobile gadget industry through the utilization of innovative machine learning techniques. To develop new models for utilizing industry datasets of customer preferences, browsing histories, and market surveys, several machine learning models, such as LSTM, DT, RF, and ANN, were used to quickly predict customer requirements with unprecedented accuracy. Based on the model performance evaluation, the ANN-factor was the most accurate, accounting for 96.67\%. Further, the demonstration would be performed following ANN-factor implementation since post-demonstrative performance indicates an increase in sales revenue by 30\%, customer engagement by 13.33\%, and market share by 25\%. This case demonstrates how the ML model has significantly changed the approach to business processes in the mobile gadget industry. The real-time demonstrated model contributed to fast decision-making, which further supported the ability to react to the market and further perform adjustments of changes formulated in product development and marketing. Consequently, the research findings could be learned and applied to industries such as non-innovative industries as well, which gain insights into happiness from changes and adjustments in business data. © 2024, Collegium Basilea. All rights reserved.},
	language = {English},
	number = {S7},
	journal = {Nanotechnology Perceptions},
	author = {Febiula, I.M.C. and Revathi, D. and Vishal Kumar, R. and Priya, P.S. and Kumar, B.R. and Sivakumar, K.},
	year = {2024},
	note = {Publisher: Collegium Basilea},
	keywords = {Machine Learning, Customer Requirements, Marketing Strategies, Sales Optimization, abstract ok},
	pages = {70--81},
}

@inproceedings{li_automating_2024,
	title = {Automating {Customer} {Needs} to {Engineering} {Characteristics} {Mapping} in {Quality} {Function} {Deployment}: {A} {Deep} {Learning} {Approach}},
	isbn = {979-835038510-6 (ISBN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201240914&doi=10.1109%2fICAIBD62003.2024.10604487&partnerID=40&md5=64d0a7bbb445e02461047517b2a1dd0d},
	doi = {10.1109/ICAIBD62003.2024.10604487},
	abstract = {Quality Function Deployment (QFD) stands as a widely utilized toolkit in product development. It offers a systematic approach to analyze customer requirements (CRs) and convert them into engineering language for product design and production. By separating CRs and engineering characteristics (ECs), QFD ensures that the final product considers both technical aspects and customer usability. Despite its historical success, QFD encounters challenges in today's business landscape. The process is typically intricate, demanding in labor, and time-consuming. QFD teams, comprising customers, designers, engineers, marketing experts, and moderators, heavily rely on the experience and expertise of designers and engineers. Decision-making is integral to the QFD process, making it less adaptable to the current fiercely competitive and time-sensitive business environment. This paper introduces a streamlined QFD method, designed to automate the process rapidly and require fewer resources from companies. Leveraging extensive online product review text, our smart QFD method deduces the relationship between CRs and ECs. The application of Graph Convolutional Network (GCN) aids in extracting features for the CRs-ECs mapping, facilitating the QFD process. Experimental results demonstrate the effectiveness of the GCN-based QFD structure. © 2024 IEEE.},
	language = {English},
	booktitle = {Int. {Conf}. {Artif}. {Intell}. {Big} {Data}, {ICAIBD}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Li, X. and Wang, Y. and Mo, D. and Liu, H.},
	year = {2024},
	note = {Journal Abbreviation: Int. Conf. Artif. Intell. Big Data, ICAIBD},
	keywords = {Deep learning, Decision making, text mining, Product design, customer needs, Quality function deployment, Customer requirements, Mapping, Engineering characteristics, Sales, Graph convolutional network, Text-mining, Convolutional networks, Learning approach, Customer need, Deployment methods, Deployment process, GCN, quality function deployment (QFD), abstract ok},
	pages = {1--5},
}

@inproceedings{goridkov_whats_2024,
	title = {What's in this {LCA} {Report}? {A} {Case} {Study} on {Harnessing} {Large} {Language} {Models} to {Support} {Designers} in {Understanding} {Life} {Cycle} {Reports}},
	volume = {122},
	isbn = {22128271 (ISSN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193501881&doi=10.1016%2fj.procir.2024.01.131&partnerID=40&md5=0c207cf19f7be5f13350f6eb65563098},
	doi = {10.1016/j.procir.2024.01.131},
	abstract = {Life cycle assessment (LCA) is a well-established approach and benchmark for design for sustainability efforts, in which detailed reports are produced that can serve as decision-making guides for developing new products. However, LCA reports are typically dense and technically complex, making it difficult for many engineering design project stakeholders to appropriately leverage the information found within them. Our work seeks to understand and improve the transfer of knowledge from LCA reports during the early stages of the design process, specifically leveraging the natural language capabilities of large language models (LLMs). In this paper, we investigate how four LCA-and sustainability-centric prompting frameworks can extract relevant design knowledge from LCA reports, demonstrated through a case study where an LLM (ChatGPT) is prompted on a provided electric toothbrush LCA report. Key findings illustrate the prompting frameworks can establish high-level summaries and identify life-cycle specific information, but the development of specific and design-focused sub-prompts will allow for richer understanding. We envision designers can use these proposed frameworks to query an LLM to gain context and insights from relevant LCA reports. The proposed techniques serve as a basis for automatic knowledge extraction from life cycle documents, creating accessible information in a user-friendly manner for designers who look to develop life-cycle-informed products. © 2024 The Author(s).},
	language = {English},
	booktitle = {Procedia {CIRP}},
	publisher = {Elsevier B.V.},
	author = {Goridkov, N. and Wang, Y. and Goucher-Lambert, K.},
	editor = {{Settineri L.} and {Priarone P.C.}},
	year = {2024},
	note = {Journal Abbreviation: Procedia CIRP},
	keywords = {Data mining, Decision making, knowledge management, sustainable design, Knowledge management, Product design, Computational linguistics, Sustainable development, Life cycle, Ecodesign, Case-studies, Natural language processing systems, Design-process, Language model, Large language model, Decisions makings, large language models, document understanding, Document understanding, Engineering design programs, Life cycle report, life cycle reports, Project stakeholders, Transfer of knowledge, abstract ok},
	pages = {964--969},
}

@article{taj_aspect_2024,
	title = {Aspect {Based} {Sentiment} {Analysis} {Using} {Modified} {Latent} {Dirichlet} {Allocation} and {Optimized} {BERT} with {LSTM} {Classification}},
	volume = {17},
	issn = {2185310X (ISSN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201519748&doi=10.22266%2fijies2024.1031.62&partnerID=40&md5=12cc179a1392e0322e100b3db07caf18},
	doi = {10.22266/ijies2024.1031.62},
	abstract = {Aspect-Based Sentiment Analysis (ABSA) is essential in industries such as healthcare, automotive, and finance, where understanding customer feedback is crucial for business strategies and product development. Traditional sentiment analysis methods often fail to account for specific aspects, providing only generalized sentiment scores (polarities). This study aims to develop a robust ABSA architecture to accurately classify aspect-based sentiment polarity. We propose a Modified Latent Dirichlet Allocation (M-LDA) model that integrates Term Frequency-Inverse Document Frequency (TF-IDF) and Latent Dirichlet Allocation (LDA) to extract relevant aspects. Additionally, an Optimized Bidirectional Encoder Representations from Transformers (O-BERT) model is used to determine aspect-based sentiment polarity, categorizing sentiments as positive, negative, or neutral. A Long Short-Term Memory (LSTM) network is then employed to enhance classification accuracy. The M-LDA O-BERTLSTM for ABSA (MOL-ABSA) performance, evaluated using accuracy and macro-F-score metrics on the SemEval 2014 and a generalized dataset, demonstrates its effectiveness, achieving accuracies of 81.19\%, 85.26\%, and 87.53\%, respectively. This integrated approach combines traditional NLP techniques with advanced machine learning models to ensure high accuracy. © (2024), (Intelligent Network and Systems Society). All rights reserved.},
	language = {English},
	number = {5},
	journal = {International Journal of Intelligent Engineering and Systems},
	author = {Taj, N.M.B. and Shivappa, G.G.},
	year = {2024},
	note = {Publisher: Intelligent Network and Systems Society},
	keywords = {BERT, LDA, ABSA, SemEval 2014, TF-IDF, abstract ok},
	pages = {825--835},
}

@inproceedings{mitra_hybrid_2024,
	title = {A {Hybrid} {Framework} {Using} {Natural} {Language} {Processing} and {Collaborative} {Filtering} for {Performance} {Efficient} {Feedback} {Mining} and {Recommendation}},
	volume = {1053 LNEE},
	isbn = {18761100 (ISSN); 978-981993480-5 (ISBN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180152784&doi=10.1007%2f978-981-99-3481-2_40&partnerID=40&md5=aa1a859f9a107bf6714fd7580c3690a2},
	doi = {10.1007/978-981-99-3481-2_40},
	abstract = {Product development insights may be found through user reviews on App stores, product forums, and social media. This feedback is often regarded as the “voice of the users”. This feedback has been subject to a lot of recent research, intending to create systems that can automatically extract, filter, analyze, and report the concerned feedback data in near real time. As per our survey results, often this user feedbacks do not reach the concerned organization promptly due to the volume, veracity, and velocity of feedback from multiple channels. In this rese arch work, we propose using sentiment analysis and social media mining an automatic engine which can be used for better product recommendation and automatic routing of relevant feedback to the product development teams. Our proposed solution is scheduled to run at regular intervals pulling dynamic reviews in an optimized manner with a lesser time complexity and higher efficiency. The reviews are collated from distributed platforms followed by building a domain classification engine on the principles of TF-IDF and Supervised Classifier. This system is used to classify the reviews of the respective enterprises. A sentiment analysis system is built using combined Rule-Based Mining and Supervised Learning Models which makes use of polarity to classify if the feedback is positive or negative. If the polarity is negative, the feedback gets routed to the concerned enterprise for immediate action and if the polarity is positive, it is passed to a user-based collaborative filtering engine which acts as a recommendation system. © 2024, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	language = {English},
	booktitle = {Lect. {Notes} {Electr}. {Eng}.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	author = {Mitra, K. and Parthasarathy, P.D.},
	editor = {{Borah M.D.} and {Laiphrakpam D.S.} and {Auluck N.} and {Balas V.E.}},
	year = {2024},
	note = {Journal Abbreviation: Lect. Notes Electr. Eng.},
	keywords = {Product development, Sentiment analysis, Social networking (online), Real time systems, Recommender systems, Collaborative filtering, Recommendation, Lexicon, Engines, Routings, Supervised classifiers, Feedback routing, Hybrid framework, Lexicons, Supervised classifier, TF-IDF vectorizer, User-based collaborative filtering, Vectorizer, abstract ok},
	pages = {527--543},
}

@inproceedings{luttmer_requirements_2023,
	title = {Requirements extraction from engineering standards - systematic evaluation of extraction techniques},
	volume = {119},
	isbn = {22128271 (ISSN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169917098&doi=10.1016%2fj.procir.2023.03.125&partnerID=40&md5=1edfba87ececca86e558d20397899f65},
	doi = {10.1016/j.procir.2023.03.125},
	abstract = {Working with information and knowledge is highly important in engineering design. Especially due to the continuous growth of information embedded in documents, the extraction process needs to be automated and accelerated. Hereby, engineering standards are an important source of knowledge in product development. However, the current way of working with these documents is inefficient and requires a lot of manual steps. This research paper focuses on the automatic extraction of requirements from standards documents and aims to systematically evaluate different extraction techniques in order to identify the best suitable technique for the given problem. For this, a dataset with approximately 10,000 entries is generated from existing standards. It is used to evaluate different extraction techniques whereas rule-based as well as supervised and unsupervised machine-learning techniques are implemented. It is shown that requirements are extracted efficiently, i.e. the F1-score is mostly greater than 80\%. This proves the overall suitability for automatic requirements extraction from standards documents. The best results are achieved by Support Vector Machine (F1-scoreSVM=89.6\%), followed by the fine-tuned BERT model (F1-scoreBERT=87.9\%). Additionally, the rule-based extraction shows promising results and should be considered in future due to its high transparency. Future work will focus on the optimization and combination of different techniques as well as the automatic integration into requirements engineering tools. © 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0)},
	language = {English},
	booktitle = {Procedia {CIRP}},
	publisher = {Elsevier B.V.},
	author = {Luttmer, J. and Prihodko, V. and Ehring, D. and Nagarajah, A.},
	editor = {{Liu A.} and {Kara S.}},
	year = {2023},
	note = {Journal Abbreviation: Procedia CIRP},
	keywords = {Engineering design, Machine learning, Information extraction, Support vector machines, Machine-learning, Requirements engineering, Learning systems, Rule based, Requirement engineering, BERT model, Engineering standards, Extraction techniques, Standard documents, Systematic evaluation, abstract ok, haben wir},
	pages = {794--799},
}

@inproceedings{oh_modeling_2022,
	title = {Modeling {Customer} {Satisfaction} based on {Kano} {Model} from {Online} {Reviews}: {Focused} on {Deep} {Learning} {Natural} {Language} {Processing}},
	isbn = {978-166546582-3 (ISBN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141440340&doi=10.1109%2fBCD54882.2022.9900513&partnerID=40&md5=07be3e271df68985f193c1b426f6a951},
	doi = {10.1109/BCD54882.2022.9900513},
	abstract = {Online reviews are data written voluntarily by customers and have become relatively easy to collect in recent years. Because it can be easily collected, online reviews can be used as alternative data to understand customer satisfaction and many studies have attempted customer satisfaction modeling by converting online reviews, which are unstructured data, into structured data. Hence, this study presented an improved framework for conducting customer satisfaction modeling from online reviews and mixed unsupervised learning and supervised learning methods. Also, this study proposed a methodology using deep learning-based natural language processing techniques to supplement the methodological limitations of existing studies and to secure structured data for customer satisfaction modeling in the absence of labeled data. The study is expected to demonstrate the necessity of a detailed product improvement strategy through modeling according to the improvement of processing techniques for review text in customer satisfaction modeling research and to provide efficient product development/improvement guidelines to promote customer satisfaction. © 2022 IEEE.},
	language = {English},
	booktitle = {Proc. - {IEEE}/{ACIS} {Int}. {Conf}. {Big} {Data}, {Cloud} {Comput}., {Data} {Sci}., {BCD}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Oh, M. and Kim, T. and Im, E.},
	editor = {{Trong V.H.} and {Park J.} and {Thao V.T.T.} and {Kim J.}},
	year = {2022},
	note = {Journal Abbreviation: Proc. - IEEE/ACIS Int. Conf. Big Data, Cloud Comput., Data Sci., BCD},
	keywords = {Deep learning, Customer satisfaction, Natural language processing, E-learning, Natural Language Processing, Unsupervised learning, Kano model, Deep Learning, Online reviews, Sales, Kano Model, Learning systems, Language processing, Natural languages, Modeling languages, Structured data, Unstructured data, Customers' satisfaction, Customer Satisfaction Modeling, Customer satisfaction models, Online Review, abstract ok},
	pages = {22--26},
}

@inproceedings{krahe_ai-based_2021,
	title = {{AI}-{Based} knowledge extraction for automatic design proposals using design-related patterns},
	volume = {100},
	isbn = {22128271 (ISSN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107868284&doi=10.1016%2fj.procir.2021.05.093&partnerID=40&md5=9da454fc92e5cdd9b3b5d76a274696a4},
	doi = {10.1016/j.procir.2021.05.093},
	abstract = {Engineering competence and the digitization of all processes along the product development process are highly decisive for today's success of industrial companies. The design process is very individual and strongly based on design engineers' experience. Part of this knowledge and the result of the design approach are fixated in the existing variations of the product generations, but are difficult to extract and to formalize. Conclusions about design-related patterns between products of different generations or variants can be drawn from the model tree representing the design engineer's thinking process for each individual CAD model. However, the model tree has hardly been used so far. The aim of this paper is to examine whether there exist any common design patterns between CAD models of certain component classes by the exemplary use case in the area of mechanical engineering. To identify patterns and to extract knowledge out of complex data sets, Machine Learning (ML), especially Deep Learning, has proven an immense capability. Finally, based on the learned patterns, meaningful next design steps are to be proposed in the form of an assistance system. The results show that there exist common design patterns for various classes of components. It is illustrated on an exemplary component class that those patterns can be used to train an assistance system based on Recurrent Neural Networks (RNNs). The corresponding design patterns were extracted from data of an industrial application partner. By transferring these design patterns to the development of new product generations or variants, on the one hand the design process itself and thus the time to market can be shortened. On the other hand, the knowledge from previous product generations contained in those patterns can be preserved. For further research the design patterns of CAD models extracted by ML algorithms is a contribution to faster knowledge extrapolation. © 2021 Elsevier B.V.. All rights reserved.},
	language = {English},
	booktitle = {Procedia {CIRP}},
	publisher = {Elsevier B.V.},
	author = {Krahe, C. and Kalaidov, M. and Doellken, M. and Gwosch, T. and Kuhnle, A. and Lanza, G. and Matthiesen, S.},
	year = {2021},
	note = {Journal Abbreviation: Procedia CIRP},
	keywords = {abstract ok, Artificial Intelligence, Assistance system, Automatic design, CAD models, Computer aided design, Data mining, Design, Design engineers, Design Patterns, Design proposal, Design-process, Forestry, Knowledge extraction, Model trees, Pattern recognition, Pattern Recognition, Product design, Product development, Product Development, Product generation, Recurrent neural networks},
	pages = {397--402},
	file = {Volltext:C\:\\Users\\Sontag\\Zotero\\storage\\98JNESJ8\\Krahe et al. - 2021 - AI-Based knowledge extraction for automatic design.pdf:application/pdf},
}

@article{liu_new_2020,
	title = {A new function-based patent knowledge retrieval tool for conceptual design of innovative products},
	volume = {115},
	issn = {01663615 (ISSN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075516367&doi=10.1016%2fj.compind.2019.103154&partnerID=40&md5=db148a285b26232a9d2b6570cbafab08},
	doi = {10.1016/j.compind.2019.103154},
	abstract = {The reuse of design knowledge within a specific domain is currently a major research focus in product design. However, the importance of support from cross-domain knowledge is steadily on the increase for product innovative design, which includes multi-domain knowledge recombination, transfer and transformation. As the biggest knowledge provider, patent information plays an irreplaceable role inspiring designers in the conceptual design stage. Nevertheless, it is of a great importance and also an issue to figure out how to efficiently retrieve cross-domain patents. In this paper, we propose a function-based patent knowledge retrieval tool for conceptual design of innovative products. In order to establish the underlying local database, function information, technical terms and International Patent Classification (IPC) information are respectively extracted from patents crawled on Websites to represent function, technology and domain properties, thereby generating a patent knowledge space. Particularly, by using a semi-supervised learning algorithm, function information is automatically classified and labeled by functional basis, into which the design problem is abstracted and interpreted forming a design problem space. By functional basis mapping from the design problem space to the patent knowledge space, we retrieve the required cross-domain patents, which are then clustered and evaluated in accordance with the extracted technology and domain properties. The selected patents are thus purposefully recommended to trigger designers’ creativity. Finally, a case study illustrates the conceptual design process based on the proposed retrieval tool. In addition to that, we conducted an experiment to verify our tool. It demonstrates that our proposed tool can assist designers to generate more ideas and the novelty of ideas is higher. © 2019 Elsevier B.V.},
	language = {English},
	journal = {Computers in Industry},
	author = {Liu, L. and Li, Y. and Xiong, Y. and Cavallucci, D.},
	year = {2020},
	note = {Publisher: Elsevier B.V.},
	keywords = {abstract ok, Classification (of information), Conceptual design, Conceptual design stages, Data mining, Functional basis, Innovative design, International patents, Knowledge retrieval, Learning algorithms, Learning systems, Machine learning, Patent evaluation, Patent information, Patents and inventions, Product design, Product innovative design, Supervised learning, TRIZ},
}

@inproceedings{zhang_unsupervised_2020,
	title = {An unsupervised deep learning model to discover visual similarity between sketches for visual analogy support},
	volume = {8},
	isbn = {978-079188397-6 (ISBN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096187973&partnerID=40&md5=3ecff9923e35b62343d46f65d2d247c7},
	abstract = {Visual analogy has been recognized as an important cognitive process in engineering design. Human free-hand sketches provide a useful data source for facilitating visual analogy. Although there has been research on the roles of sketching and the impact of visual analogy in design, little work has been done aiming to develop computational tools and methods to support visual analogy from sketches. In this paper, we propose a computational method to discover visual similarity between sketches, considering the following practical application: Given a sketch drawn by a designer that reflects the designer's rough idea in mind, our goal is to identify the shape similar sketches that can stimulate the designer to make more and better visual analogies. The first challenge in doing so is how to discover the similar shape features embedded in sketches from various categories. To address this challenge, we propose a deep clustering model to learn a latent space which can reveal underlying shape features for multiple categories of sketches and cluster sketches simultaneously. An extensive evaluation of the clustering performance of our proposed method has been carried out in different configurations. The results have shown that the proposed method can discover sketches that have similar appearance, provide useful explanations of the visual relationship between different sketch categories, and has the potential to generate visual stimuli to enhance designers' visual imageries. © 2020 American Society of Mechanical Engineers (ASME). All rights reserved.},
	language = {English},
	booktitle = {Proc. {ASME} {Des}. {Eng}. {Tech}. {Conf}.},
	publisher = {American Society of Mechanical Engineers (ASME)},
	author = {Zhang, Z. and Jin, Y.},
	year = {2020},
	note = {Journal Abbreviation: Proc. ASME Des. Eng. Tech. Conf.},
	keywords = {abstract ok, Clustering model, Cognitive process, Computation theory, Computational methods, Computational tools, Deep learning, Design, Design by analogy, Drawing (graphics), Engineering design, Engineering research, Fixation, Image enhancement, Learning models, Sketching, Unsupervised deep learning, Visual analogies, Visual similarity, Visual stimulus},
}

@inproceedings{wang_proposal_2019,
	title = {A proposal for service design based on user's action history using machine learning},
	isbn = {978-172813179-5 (ISBN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087651851&doi=10.1109%2fInformatics47936.2019.9119266&partnerID=40&md5=31fa779911963d27ca562dc022b51969},
	doi = {10.1109/Informatics47936.2019.9119266},
	abstract = {With the development of IoT techniques, it become easier to collect users' action data. By analyzing and using those data, consumers and producers will mutually exchange their intelligence and better customize product development processes. This study examines a proposed system using sensor shoes with several sensor devices embedded in the insoles, collecting action data of users, extracting their action features, and then issuing some advice to help users train more efficiently. As described herein, a service model uses a backpropagation (BP) network to distinguish users' actions and to extract their action features using using Self-organization Map from the presented sensing data. Finally, we review their performance via experimentation. © 2019 IEEE.},
	language = {English},
	booktitle = {{INFORMATICS} - {IEEE} {Int}. {Sci}. {Conf}. {Informatics}, {Proc}.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Wang, X. and Fujii, N. and Kaihara, T. and Kokuryo, D.},
	year = {2019},
	note = {Journal Abbreviation: INFORMATICS - IEEE Int. Sci. Conf. Informatics, Proc.},
	keywords = {Data mining, Machine learning, Neural network, Product development process, Service Design, Self-organizing map, Service design, Self-organization maps, Collector efficiency, Sensor device, Backpropagation network, Sensing data, Service Model, abstract ok},
	pages = {267--272},
}

@inproceedings{fels_extracting_2019,
	title = {Extracting {Customer}-{Related} {Information} for {Need} {Identification}},
	volume = {876},
	isbn = {21945357 (ISSN); 978-303002052-1 (ISBN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055798968&doi=10.1007%2f978-3-030-02053-8_169&partnerID=40&md5=ade26dbc97a96d04bc96180820bf9076},
	doi = {10.1007/978-3-030-02053-8_169},
	abstract = {The increasing amounts of customer-generated content regarding a product or service published in Social Media are an important source of information for companies. Especially for product development projects or the design of service offers, the unbiased feedback expressed in so-called product reviews is most valuable. However, for the effective use of product review content, the development of automated text processing tools is essential; manual text processing approaches are very time-consuming and thus compromise the benefits provided from the extracted information. To date, automated text mining tools focus the analysis of customers preferences and emotions articulated within a product review. An automated extraction and analysis of customer-related content has not yet been investigated in detail. Customer-related content refers to information within a review, which does not primarily concern the product, but provide information about the customer himself, his usage behavior, personal environment and habits. This information is most generally expressed in an objective manner by the author (i.e. customer) and provides an authentic starting point for the identification of customer needs. Particularly for innovative product development, the consideration of customer habits and personal environment is highly relevant for the derivation of underlying needs, which can be more important than the knowledge of specific preferences regarding a product. The objective of this research is the development and validation of a text mining process for the extraction of objective content from product reviews. To this end, German reviews from Amazon.de regarding two product categories are collected and firstly annotated manually for validation reference. Thereafter, a text mining process is developed comprising text preparation, transformation, classification and performance evaluation. Three different classifiers are applied for performance comparison. © 2019, Springer Nature Switzerland AG.},
	language = {English},
	booktitle = {Adv. {Intell}. {Sys}. {Comput}.},
	publisher = {Springer Verlag},
	author = {Fels, A. and Briele, K. and Ellerich, M. and Schmitt, R.},
	editor = {{Ahram T.} and {Taiar R.} and {Karwowski W.}},
	year = {2019},
	note = {Journal Abbreviation: Adv. Intell. Sys. Comput.},
	keywords = {Data mining, Product development, Automation, Product design, Social networking (online), Systems engineering, Social media analysis, Sales, Text classification, Product development projects, Classification (of information), Extraction, Text processing, Performance comparison, Innovative product development, Automated text processing, Performance evaluations, Related content, User-related content, abstract ok},
	pages = {1108--1112},
}

@inproceedings{li_text_2018,
	title = {A {Text} {Mining} based {Reliability} {Analysis} {Method} in {Design} {Failure} {Mode} and {Effect} {Analysis}},
	isbn = {978-153861164-7 (ISBN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061958577&doi=10.1109%2fICPHM.2018.8448909&partnerID=40&md5=d768d21eb4e0c6f61c2e7fd736afcd75},
	doi = {10.1109/ICPHM.2018.8448909},
	abstract = {Failure Mode and Effects Analysis (FMEA) is one of the basic and the most commonly used techniques in reliability analysis and management. Design FMEA is the application of the FMEA method in product development phase and have shown remarkable results in various engineering design fields. DFMEA reports usually contain a lot of text information about quality and reliability improvement opportunities for new product development. However, it can be very difficult and non-intuitive to fully understand these text information for design improvements. To address this challenge, we propose to apply text mining methods in DFMEA reports to discover the hidden reliability information. Specifically, three types of hidden information are investigated, which include the correlation of the failure related features in the potential failure mode or failure cause, the classification of failure modes and causes, and the optimal set of improvement activities according to the effect and cost metric proposed in this paper. Among them, one feature represents a failure characteristic or a location of the potential failure mode or failure cause (e.g. wear, break, bend, surface, insert, stem). These three pieces of information can be further integrated to product verification and validation process for effective risk identification and mitigation in a more economic and effective way. Finally, we illustrate the application of the text mining methods in DFMEA report for a subsystem in a power generation system within a diesel engine. © 2018 IEEE.},
	language = {English},
	booktitle = {{IEEE} {Int}. {Conf}. {Progn}. {Heal}. {Manag}., {ICPHM}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Li, Z. and Wu, G.},
	year = {2018},
	note = {Journal Abbreviation: IEEE Int. Conf. Progn. Heal. Manag., ICPHM},
	keywords = {abstract ok, classification, Classification (of information), correlation, Correlation methods, Data mining, DFMEA, Diesel engines, Failure (mechanical), Failure characteristics, Failure mode and effects analysis, Failure modes, Optimal sets, Outages, Potential failure modes, Power generation systems, Product design, Product development, Reliability analysis, Reliability analysis method, Systems engineering, Text mining, Text Mining, Text processing, the optimal set},
	file = {Volltext:C\:\\Users\\Sontag\\Zotero\\storage\\VCRUD2TK\\Li und Wu - 2018 - A Text Mining based Reliability Analysis Method in.pdf:application/pdf},
}

@article{akella_gain_2017,
	title = {Gain {Customer} {Insights} {Using} {NLP} {Techniques}},
	volume = {10},
	issn = {19463979 (ISSN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042318537&doi=10.4271%2f2017-01-0245&partnerID=40&md5=229eb8055b81adcea51e7192ec3c83f9},
	doi = {10.4271/2017-01-0245},
	abstract = {Voice of customer is typically captured through multiple connect points like surveys, warranty claims, social media, and so on. Customer verbatim is collected through these connect points to encourage free expression of opinion by customers. Such verbatim data is generally of high value and is typically analyzed using Natural Language Processing (NLP) techniques for translating into influencing actions in manufacturing, customer service, marketing, and product development departments. One of the challenges in analyzing unstructured verbatim data is to map that data onto appropriate concern codes (CCCs), which are typically used in automotive firms for tracking quality and satisfaction metrics. These concern codes map to a hierarchy of function areas in the organization aimed at improving product, service and hence the customer’s overall experience. In this paper, we discuss our approach to address the challenge of mapping customer verbatim to concern codes, which is a classical natural language text classification problem. In this work, verbatim inputs from transactional systems of quality office, warranty claims, issues matrix, surveys, and social media content are used. Diverse sources and format of these textual comments pose challenges with free flow writing, content, language, and abbreviations. We apply traditional approaches of word counts and TF-IDF for representing documents. Considering complexity of word relationships, we adopt word embedding using word2vec to derive document vector representation of text. Machine learning models are then used to classify customer comments into concern codes. As next steps, we plan to use translation techniques to extend this comment classification framework for English to other languages. Copyright © 2017 SAE International.},
	language = {English},
	number = {3},
	journal = {SAE International Journal of Materials and Manufacturing},
	author = {Akella, K. and Venkatachalam, N. and Gokul, K. and Choi, K. and Tyakal, R.},
	year = {2017},
	note = {Publisher: SAE International},
	keywords = {classification, text analytics, natural language processing, Text analytics, Support vector machines, Social networking (online), word embedding, SVM, Sales, SGD, Surveys, Classification (of information), Codes (symbols), Natural language processing systems, Text processing, Embeddings, NAtural language processing, word2vec, Translation (languages), TF-IDF, Manufacturing data processing, abstract ok},
	pages = {333--337},
}

@inproceedings{pajo_fast_2015,
	title = {Fast lead user identification framework},
	volume = {131},
	isbn = {18777058 (ISSN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960539547&doi=10.1016%2fj.proeng.2015.12.434&partnerID=40&md5=416aa038b6074e398ba6e37f7ebc448a},
	doi = {10.1016/j.proeng.2015.12.434},
	abstract = {Large portion of product innovation and development is accomplished by customers and only a small segment of the customer population engages in such innovation activities. Empirical research has shown that users in this subgroup, called lead users, tend to experience needs before the rest of the marketplace and stand to benefit greatly by finding solutions to those needs. To meet the challenge of quickly and effectively identifying lead users and uncovering their innovation ideas, the authors propose a fast and systematic approach, called Fast Lead User IDentification (FLUID), utilizing data mining techniques to identify lead users on social networking sites. The paper describes the steps taken to build and optimize the FLUID system to effectively identify lead users on the micro-blogging site Twitter. This entails studies using validated lead user questionnaires resulting in clusters of lead and non-lead Twitter users for a single product. The gathered online user metadata and behavior are then used as training data for the automated system. An overview of data processing techniques and relations to the empirically derived lead user characteristics are presented. Finally, classification algorithms that help to separate lead users from non-lead users are discussed, including optimization leading to the validation of the proposed approach. By making use of data-mining techniques on data rich sites like social networking sites, the FLUID approach minimizes the resource and time costs in identifying lead users and this provides a step towards systematizing the fuzzy-front end of the new product development process. © 2015 The Authors. Published by Elsevier Ltd.},
	language = {English},
	booktitle = {Procedia {Eng}.},
	publisher = {Elsevier Ltd},
	author = {Pajo, S. and Verhaegen, P.-A. and Vandevenne, D. and Duflou, J.R.},
	editor = {{Cavallucci D.} and {Duflou J.} and European TRIZ Association ETRIA e.V., Freiburg, Basler Str. 115 and {Livotov P.} and European TRIZ Association ETRIA e.V., Freiburg, Basler Str. 115 and {Vaneker T.} and European TRIZ Association ETRIA e.V., Freiburg, Basler Str. 115 and {Cascini G.} and Politecnico di Milano, via La Masa 1, Milano, Dept. of Mechanical Engineeing and {Cascini G.} and European TRIZ Association ETRIA e.V., Freiburg, Basler Str. 115 and {Livotov P.} and Offenburg University of Applied Sciences, Offenburg, Badstr. 24 and {Cavallucci D.} and European TRIZ Association ETRIA e.V., Freiburg, Basler Str. 115 and {Duflou J.} and KU Leuven, Dep. of Mechanical Engineering, Celestijnenlaan 300A, Leuven, Centre for Industrial Management and {Vaneker T.} and University of Twente, Enschede, Drienelerlolaan 5},
	year = {2015},
	note = {Journal Abbreviation: Procedia Eng.},
	keywords = {Data mining, Product development, Innovation, Automation, Social media, Social networking (online), Problem solving, New product development process, Systematic innovation, Fuzzy front end, Lead user, Surveys, Knowledge based systems, Behavioral research, Data handling, Lead users, Classification algorithm, Data processing techniques, Fuzzy-front end, Innovation activity, Social networking sites, abstract ok},
	pages = {1140--1145},
}

@article{danglade_use_2014,
	title = {On the use of {Machine} {Learning} to {Defeature} {CAD} {Models} for {Simulation}},
	volume = {11},
	issn = {16864360 (ISSN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890036392&doi=10.1080%2f16864360.2013.863510&partnerID=40&md5=58cf464fa94083c4b4dae67d3e0a28fd},
	doi = {10.1080/16864360.2013.863510},
	abstract = {Numerical simulations play more and more important role in product development cycles and are increasingly complex, realistic and varied. CAD models must be adapted to each simulation case to ensure the quality and reliability of the results. The defeaturing is one of the key steps for preparing digital model to a simulation. It requires a great skill and a deep expertise to foresee which features have to be preserved and which features can be simplified. This expertise is often not well developed and strongly depends of the simulation context. In this paper, we propose an approach that uses machine learning techniques to identify rules driving the defeaturing step. The expertise knowledge is supposed to be embedded in a set of configurations that form the basis to develop the processes and find the rules. For this, we propose a method to define the appropriate data models used as inputs and outputs of the learning techniques. © 2013 © 2013 CAD Solutions, LLC.},
	language = {English},
	number = {3},
	journal = {Computer-Aided Design and Applications},
	author = {Danglade, F. and Pernot, J.-P. and Véron, P.},
	year = {2014},
	note = {Publisher: Taylor and Francis Inc.},
	keywords = {abstract ok, CAD model defeaturing, CAD models, Computer aided design, Computer simulation, decision making, Decision making, Defeaturing, Digital model, Learning systems, Learning techniques, machine learning, Machine learning techniques, Product development, Product development cycle, simulation},
	pages = {358--368},
}

@inproceedings{yan_work-centered_2012,
	title = {A work-centered visual analytics model to support engineering design with interactive visualization and data-mining},
	isbn = {15301605 (ISSN); 978-076954525-7 (ISBN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863246357&doi=10.1109%2fHICSS.2012.87&partnerID=40&md5=d9b37b403a1bb90772df9da366518a29},
	doi = {10.1109/HICSS.2012.87},
	abstract = {To support the knowledge discovery and decision making from large-scale, multi-dimensional, continuous data sets, novel systems of visual analytics need the capability to identify hidden patterns in data that are critical for in-depth analysis. In this paper, we present a work-centered approach to support visual analytics of complex data sets by combining usercentered interactive visualization and data-oriented computational algorithms. We design and implement a specific system prototype, Learning-based Interactive Visualization for Engineering design (LIVE), for engineering designers to handle overwhelming information such as numerous design alternatives generated from automatic simulating software. During the exploration within a "trade space" consisting of possible designs and potential solutions, engineering designers want to analyze the data, discover hidden patterns, and identify preferable solutions. The proposed system allows designers to interactively examine large design data sets through visualization and interactively construct data models from automatic data mining algorithms. We expect that our approach can help designers efficiently and effectively make sense of large-scale design data sets and generate decisions. We also report a preliminary evaluation on our system by analyzing a real engineering design problem related to aircraft wing sizing. © 2012 IEEE.},
	language = {English},
	booktitle = {Proc. {Annu}. {Hawaii} {Int}. {Conf}. {Syst}. {Sci}.},
	publisher = {IEEE Computer Society},
	author = {Yan, X. and Qiao, M. and Li, J. and Simpson, T.W. and Stump, G.M. and Zhang, X.},
	year = {2012},
	note = {Journal Abbreviation: Proc. Annu. Hawaii Int. Conf. Syst. Sci.},
	keywords = {abstract ok, Computational algorithm, Data mining, Data mining algorithm, Data visualization, Decision making, Design alternatives, Design and implements, Engineering design, Engineering designer, Engineering education, Fighter aircraft, Interactive visualizations, Multi dimensional, Visualization, Wings},
	pages = {1845--1854},
}

@article{chen_problem-solving_2009,
	title = {A problem-solving approach to product design using decision tree induction based on intuitionistic fuzzy},
	volume = {196},
	issn = {0377-2217},
	url = {https://www.sciencedirect.com/science/article/pii/S0377221708002841},
	doi = {10.1016/j.ejor.2008.03.009},
	abstract = {Customer complaint problem is a product design used to understand customer requirements. Furthermore, product design corresponding to customer requirement does not feel adequately solved for a cause of problem. The cause of the problem affecting product design is solved to prevent customer complaint from reoccurring. However, the problems by customer may have observation uncertainty and fuzzy. Fuzzy concept considers not only the degree of membership to an accept set, but also the degree of non-membership to a rejection set. Therefore, we present a new approach for problem solving using decision tree induction based on intuitionistic fuzzy sets in this paper. Under this approach, we first develop the problem formulation for the symptoms and causes of the problem based on intuitionistic fuzzy sets. Next, we identify the cause of the problem using intuitionistic fuzzy decision tree by the problem formulation. We then provide the approach to find the optimal cause of the problem for the consideration of product design. A numerical example is used to illustrate the approach applied for product design.},
	number = {1},
	urldate = {2025-02-21},
	journal = {European Journal of Operational Research},
	author = {Chen, Rui-Yang},
	month = jul,
	year = {2009},
	keywords = {Product design, Problem solving, Intuitionistic fuzzy, abstract ok},
	pages = {266--272},
	file = {ScienceDirect Snapshot:C\:\\Users\\Sontag\\Zotero\\storage\\YQQVVUF9\\S0377221708002841.html:text/html},
}

@article{tucker_trend_2011,
	title = {Trend {Mining} for {Predictive} {Product} {Design}},
	volume = {133},
	issn = {1050-0472},
	url = {https://doi.org/10.1115/1.4004987},
	doi = {10.1115/1.4004987},
	abstract = {The Preference Trend Mining (PTM) algorithm that is proposed in this work aims to address some fundamental challenges of current demand modeling techniques being employed in the product design community. The first contribution is a multistage predictive modeling approach that captures changes in consumer preferences (as they relate to product design) over time, hereby enabling design engineers to anticipate next generation product features before they become mainstream/unimportant. Because consumer preferences may exhibit monotonically increasing or decreasing, seasonal, or unobservable trends, we proposed employing a statistical trend detection technique to help detect time series attribute patterns. A time series exponential smoothing technique is then used to forecast future attribute trend patterns and generates a demand model that reflects emerging product preferences over time. The second contribution of this work is a novel classification scheme for attributes that have low predictive power and hence may be omitted from a predictive model. We propose classifying such attributes as either standard, nonstandard, or obsolete by assigning the appropriate classification based on the time series entropy values that an attribute exhibits. By modeling attribute irrelevance, design engineers can determine when to retire certain product features (deemed obsolete) or incorporate others into the actual product architecture (standard) while developing modules for those attributes exhibiting inconsistent patterns throughout time (nonstandard). Several time series data sets using publicly available data are used to validate the proposed preference trend mining model and compared it to traditional demand modeling techniques for predictive accuracy and ease of model generation.},
	number = {111008},
	urldate = {2025-02-21},
	journal = {Journal of Mechanical Design},
	author = {Tucker, Conrad S. and Kim, Harrison M.},
	month = nov,
	year = {2011},
	keywords = {abstract ok},
	file = {Full Text PDF:C\:\\Users\\Sontag\\Zotero\\storage\\N9VX6J4I\\Tucker und Kim - 2011 - Trend Mining for Predictive Product Design.pdf:application/pdf;Snapshot:C\:\\Users\\Sontag\\Zotero\\storage\\J8YY7N3E\\Trend-Mining-for-Predictive-Product-Design.html:text/html},
}

@inproceedings{yazdizadeh_text_2016,
	title = {A {TEXT} {MINING} {TECHNIQUE} {FOR} {MANUFACTURING} {SUPPLIER} {CLASSIFICATION}},
	isbn = {978-0-7918-5705-2},
	abstract = {The web presence of manufacturing suppliers is constantly increasing and so does the volume of textual data available online that pertains to the capabilities of manufacturing suppliers. To process this large volume of data and infer new knowledge about the capabilities of manufacturing suppliers, different text mining techniques such as association rule generation, classification, and clustering can be applied. This paper focuses on classification of manufacturing suppliers based on the textual description of their capabilities available in their online profiles. A probabilistic technique that adopts Naive Bayes method is adopted and implemented using R programming language. Casting and CNC machining are used as the examples classes of suppliers in this work. The performance of the proposed classifier is evaluated experimentally based on the standard metrics such as precision, recall, and F-measure. It was observed that in order to improve the precision of the classification process, a larger training dataset with more relevant terms must be used.},
	author = {Yazdizadeh, P and Ameri, F and {ASME}},
	year = {2016},
	keywords = {abstract ok},
}

@article{schramm_orthogonal_2023,
	title = {Orthogonal {Procrustes} and {Machine} {Learning}: {Predicting} {Bill} of {Materials} errors on time},
	volume = {185},
	issn = {0360-8352},
	doi = {10.1016/j.cie.2023.109606},
	abstract = {In an industrial product development process, the Bill of Materials (BOM) is a hierarchical, multi-level representation of all components, parts and quantities of a product. With increasing complexity of industrial products, also BOMs become more complex and thus prone to errors, for example when the individual parts of a product are changed during the product development process. Frequently, these Bill of Materials errors have to be identified manually or by using simple, rule-based schemes. In this paper, we provide a technical background of BOMs, showing the intricacy of temporal BOMs errors in an industrial product development process. The work of other authors, which focused on association mining and tree reconciliation to detect Bill of Materials errors, is analysed. We found that there is currently no system being able to prescribe where in a Bill of Materials and when in the product development process, errors are probable to occur. Also, Machine Learning (ML) methods have not been applied yet. Based on these findings, we formalize the notions Bill of Materials and Bill of Materials errors. Furthermore, we present a deterministic distance measure for BOMS. We provide an answer to the main question of how to represent a Bill of Materials for Machine Learning tasks by solving the orthogonal Procrustes problem for dynamic, hierarchical datasets. Then, we describe an isolation forest based approach to temporal anomaly detection, which points at potential errors in a Bill of Materials at a specific timestamp. Furthermore, we apply Machine Learning and present a multi-output Multi Layer Perceptron for the prediction of temporal Bill of Materials errors. The model predicts where and at which point of time Bill of Materials errors are probable to occur, which renders it a prescriptive system. Eventually, we optimize the performance of our model using contextualization via k-means clustering. Finally, we apply our prescriptive pipeline to a real world dataset and show its superiority to existing methods using a qualitative comparison.},
	journal = {COMPUTERS \& INDUSTRIAL ENGINEERING},
	author = {Schramm, S and Pieper, M and Vogl, S},
	month = nov,
	year = {2023},
	keywords = {abstract ok, Anomaly detection, Bill of materials, Bill of Materials, Errors, Isolati on forest, k-means clustering, K-means clustering, K-means++ clustering, Machine learning, Machine-learning, Multi Layer Perceptron, Multi-output, Multi-output model, Multilayers perceptrons, Orthogonal procrustes, Orthogonal Procrustes, Procrustes, Product development, Product development process},
}

@article{shi_sequential_2017,
	title = {Sequential {Radial} {Basis} {Function} {Using} {Support} {Vector} {Machine} for {Expensive} {Design} {Optimization}},
	volume = {55},
	issn = {0001-1452},
	doi = {10.2514/1.J054832},
	abstract = {To improve the efficiency and quality of solving expensive engineering design optimization problems, recently metamodel-based design and optimization technologies have been widely employed. In this paper, a novel adaptive metamodel-based optimization method called sequential radial basis function using support vector machine is proposed to solve the practical engineering optimization problems involving computationally expensive objective and constraints. The proposed metamodel-based optimization method uses the radial basis function metamodel to approximate the expensive simulations in the interesting sampling region, which is a subregion of the design space. To identify the interesting sampling region, a novel feature space fuzzy c-means clustering method is proposed to obtain the cluster center of superior cheap points classified by support vector machine. The procedure of sequential radial basis function using support vector machine is presented first, and the interesting sampling region and feature space fuzzy c-means clustering methods are discussed in detail. Several numerical benchmark problems are used to compare the proposed method with other well-known metamodel-based design and optimization methods including efficient global optimization, multiple surrogate efficient global optimization methodology, mode-pursuing sampling, constraint importance mode pursuing sampling, and constrained optimization by radial basis function interpolation. The comparison results show that the proposed method generally outperforms the competitive methods in terms of efficiency, convergence, and robustness. Finally, sequential radial basis function using support vector machine is applied in an Earth observation satellite multidisciplinary design optimization problem. The results illustrate that compared with genetic algorithm and sequential quadratic programming, the proposed method can find a better solution with fewer function evaluations, which demonstrates the practicality and effectiveness of the proposed method in solving real-world engineering design optimization problems.},
	number = {1},
	journal = {AIAA JOURNAL},
	author = {Shi, RH and Liu, L and Long, T and Liu, J},
	month = jan,
	year = {2017},
	keywords = {abstract ok, Cluster analysis, Constrained optimization, Design, Design aids, Design and optimization, Earth observation satellites, Efficiency, Efficient global optimization, Engineering design optimization, Functions, Fuzzy c-means clustering method, Fuzzy systems, Genetic algorithms, Global optimization, Image segmentation, Importance sampling, Multidisciplinary design optimization, Numerical methods, Optimization, Quadratic programming, Radial basis function interpolation, Radial basis function networks, Sequential quadratic programming, Support vector machines, Vector spaces, Vectors},
	pages = {214--227},
}

@article{fang_active-learning_2022,
	title = {An active-learning probabilistic neural network for feasibility classification of constrained engineering optimization problems},
	volume = {38},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109050282&doi=10.1007%2fs00366-021-01441-4&partnerID=40&md5=157cb1249554d7dd1b4c2ba3db3754d4},
	doi = {10.1007/s00366-021-01441-4},
	abstract = {Constrained optimization problems (COPs) with multiple computational expensive constraints are commonly encountered in simulation-based engineering designs. During the optimization process, the feasibility analysis of the intermediate solutions depends on the computational simulations will be computationally prohibitive. To relieve this computational burden, an active-learning probabilistic neural network (AL-PNN) classification modeling approach is proposed to build a classifier for quickly analyzing the feasibility of the intermediate solutions. In the proposed AL-PNN approach, an interesting region tracking strategy is developed to locate the regions that may contain part of the constraint boundary. The judge rule of the interesting region is based on whether the predicted class labels of pseudo points are different in subregions, which is generated by dividing the design space with the K-means cluster algorithm. Once the interesting region is located, the newly infill sample point used to update the PNN classification model can be obtained by a distance screening criterion. Seven numerical cases and the design of the rocket interstage section are used to demonstrate the performances of the proposed approach. The results illustrate that the proposed AL-PNN approach can provide more accurate classification results than the compared four state-of-the-art algorithms. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.},
	journal = {Engineering with Computers},
	author = {Fang, D. and Zhang, T. and Wu, F.},
	year = {2022},
	keywords = {abstract ok, Active learning, Active Learning, Classification models, Computational expensive constraint, Computational expensive constraints, Constrained engineering optimization problems, Constrained optimi-zation problems, Constrained optimization, Constrained optimization problems, Engineering design, K-means clustering, Learning systems, Neural networks, Neural-networks, Particle swarm optimization (PSO), Probabilistic neural network, Probabilistics, Rockets, Screening, Simulation-based engineerings},
	pages = {3237--3250},
}

@article{ririn_supervised_2024,
	title = {Supervised multilabel classification techniques for categorising customer requirements during the conceptual phase in the new product development},
	volume = {16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190546153&doi=10.2478%2femj-2024-0003&partnerID=40&md5=0b579819970902018fef0e58e2595e30},
	doi = {10.2478/emj-2024-0003},
	abstract = {The research aims to provide the decision-maker with a framework for determining customer requirements during product development. The proposed framework is based on sentiment analysis and supervised multilabel classification techniques. Therefore, the proposed technique can categorise customer reviews based on the “product design criteria” label and the “sentiment of the review” label. To achieve the research goal, the research presented in this article uses the existing product development framework presented in the literature. The modification is conducted especially in the conceptual stage of product development, in which the voice of the customer or a customer review is obtained from the scraping, and a multilabel classification technique is performed to categorise customer reviews. The proposed framework is tested by using the set data on women's clothing reviews from an e-commerce site downloaded from www.kaggle.com based on data by Agarap (2018). The result shows that the proposed framework can categorise customer reviews. The research presented in this paper has contributed by proposing a technique based on sentiment analysis and multilabel classification that can be used to categorise customers during product development. The research presented in this paper answers one of the concerns in the categorisation of needs raised by Shabestari et al. (2019), namely, the unclear rules or main attributes of a requirement that make these needs fall into certain categories. Categorising customer requirements allows decision-makers to determine the direction of product development to meet customer needs. © 2024 Sutrilastyo and R. D. Astanti.},
	number = {1},
	journal = {Engineering Management in Production and Services},
	author = {Ririn, S. and Astanti, D.},
	year = {2024},
	keywords = {conceptual design, Conceptual design, Decision making, Product development, sentiment analysis, Sentiment analysis, Product design, Product development process, product development process, customer needs, voice of customer, Customer requirements, Sales, Classification (of information), Multi-label classifications, Customer need, Voices of customers, Customer review, Classification technique, abstract ok, Customer requirement categorization, customer's requirement categorisation, supervised multilabel classification technique, Supervised multilabel classification technique},
	pages = {31--47},
}

@article{huang_design_2021,
	title = {Design for {Reliability} through {Text} {Mining} and {Optimal} {Product} {Verification} and {Validation} {Planning}},
	volume = {70},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102229498&doi=10.1109%2fTR.2019.2938151&partnerID=40&md5=d27994180edfb3943e321a837f42e3d2},
	doi = {10.1109/TR.2019.2938151},
	abstract = {Failure mode and effects analysis (FMEA) has been widely used in product design process as a reliability analysis technique. Design FMEA (DFMEA), which is used in the product development phase to identify and mitigate product risk, is one of the three application scenarios of FMEA. During the DFMEA process, verification and validation (V\&V) activities are proposed to mitigate the risk of the identified potential failure modes. The V\&V activities can be further planned and implemented to improve the product reliability under development. However, the DFMEA report usually contains rich text descriptions of potential failure modes and causes, and it is difficult and nonintuitive to fully understand these information for design improvements. In addition, it is also very challenging to optimize the planning of V\&V activities by selecting a set of V\&V activities to achieve expected reliability improvement effectiveness with the minimum resource consumption requirement. To address these two challenges, this article first proposes a method of applying text mining to the DFMEA report to obtain two types of hidden reliability information, including the classifications of failure modes/causes and the correlation between keywords. Then, a mathematical model is proposed to optimize the product V\&V planning by selecting an optimal set of V\&V activities. The application of the above proposed methods is illustrated through the product development of a diesel engine power generation system. © 1963-2012 IEEE.},
	number = {1},
	journal = {IEEE Transactions on Reliability},
	author = {Huang, Q. and Wu, G. and Li, Z.S.},
	year = {2021},
	keywords = {abstract ok, Application scenario, Classification (of information), Classifications of failure modes/causes, correlation between keywords, design failure mode and effect analysis (DFMEA), Design for reliability, Failure mode and effects analysis, Failure modes, optimal set, Outages, Potential failure modes, Product design, Product design process, Product development, Reliability analysis, Reliability improvement, Reliability information, Risk perception, text mining, Text mining, verification and validation (V\&V), Verification-and-validation},
	pages = {231--247},
}

@article{stromberg_efficient_2020,
	title = {Efficient detailed design optimization of topology optimization concepts by using support vector machines and metamodels},
	volume = {52},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070799187&doi=10.1080%2f0305215X.2019.1646258&partnerID=40&md5=244ee31229a2b069b403490def2acf6a},
	doi = {10.1080/0305215X.2019.1646258},
	abstract = {In this article, an approach for metamodel-based design optimization (MBDO) of topology optimization (TO) concepts is proposed by using support vector machines (SVMs) as geometric models of the concepts instead of traditional parametric computer aided design (CAD) models. In such a manner, an efficient approach for the MBDO-driven design of TO-based concepts is obtained. An implicit hypersurface representing the TO-based concept is generated by classifying the TO-solutions of zeros and ones by using the 1-norm SVM of Mangasarian. The implicit SVM-based hypersurfaces are then utilized to set up designs of experiments of nonlinear finite element analyses by morphing the TO-based concepts by using Boolean and blending operations. Finally, MBDO is performed by using an ensemble of metamodels consisting of quadratic regression, Kriging, radial basis function networks, polynomial chaos expansion and support vector regression models. The proposed MBDO framework is demonstrated by minimizing the mass of a three-dimensional design domain with a constraint on the plastic limit load. The performance of the approach is most promising. © 2019, © 2019 The Author(s). Published by Informa UK Limited, trading as Taylor \& Francis Group.},
	number = {7},
	journal = {Engineering Optimization},
	author = {Strömberg, N.},
	year = {2020},
	keywords = {abstract ok, Blending, Computer aided design, Computer aided design models, Meta model, Metamodel-based design optimizations, metamodels, Non-linear finite-element analysis, Polynomial chaos expansion, Radial basis function networks, Regression analysis, Shape optimization, Support vector machine (SVMs), Support vector machines, Support vector regression models, Three-dimensional designs, Topology, topology optimization, Vectors},
	pages = {1136--1148},
}

@inproceedings{feldhusen_artificial_2014,
	title = {Artificial neural networks to optimize the conceptual design of adaptable product development},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84912105618&partnerID=40&md5=3bd3e77fc90c47ccde987b134b8588a6},
	abstract = {This paper describes an approach to apply Artificial Neural Network (ANN) to support the developer to optimize the conceptual design of Adaptable Product Development. The ANN learn from the previously mapping between the requirements and the product solutions. For a new development Process of an Adaptable Product the ANN analyse existing solution and sort them according to their probability of success. The advantages of this approach is on the one hand that ANN is able to identify the best suitable product solution for a new development order and on other hand the ANN automatically store the knowledge of the developer. © Cranfield University 2009.},
	author = {Feldhusen, J. and Nagarajah, A.},
	year = {2014},
	keywords = {abstract ok, Adaptable products, Conceptual design, Development process, Engineering design, Neural network, Neural networks, Neural Networks, Probability, Probability of success, Product design, Product Design, Product development, Product Development, Product development process},
	pages = {51--56},
}

@inproceedings{stone_consumer_2013,
	title = {Consumer preference estimation from twitter classification: {Validation} and uncertainty analysis},
	volume = {7 DS75-07},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897661663&partnerID=40&md5=55c7d0fb395c07b9eb163a313da1d7f7},
	abstract = {In recent years, the membership and activity of Twitter, Facebook, blogs, and other user-generate content sites has experience significant growth. Users express their opinions regarding a wide range of topics, including consumer products and services. Thus, these sites have the potential to facilitate product design via the extraction of consumer opinion and sentiment regarding product features. A key challenge is how to appropriately extract consumer preferences from the messages. This challenge is addressed with respect to Twitter using a smartphone case study. Twitter messages regarding particular smartphone attributes are classified according to sentiment: positive, negative, or neutral. This sentiment information is then used to develop an estimate of consumer preference for particular smartphone attributes, such as battery life or screen size. Uncertainty analysis is conducted in order to assess the effects of sentiment classification accuracy. Validation techniques indicate that a revised framework would be useful for predicting consumer decisions and facilitating product design; however refinement in terms of comprehensiveness and accuracy or needed. © 2013 The Design Society.},
	author = {Stone, T.M. and Choi, S.-K.},
	year = {2013},
	keywords = {Decision making, New product development, Design theory, Product design, Social networking (online), Uncertainty analysis, Consumer behavior, Consumer products, Signal encoding, Sentiment classification, Smartphones, Product feature, Products and services, abstract ok, Consumer preferences, Battery life, Screen sizes},
	pages = {457--466},
}

@inproceedings{spruegel_concept_2014,
	title = {Concept of automatic detection of components within the {FE} software environment by means of artificial neural networks},
	shorttitle = {Konzept zur automatischen {Bauteilerkennung} innerhalb der {FE}-{Software}-{Umgebung} mittels {Künstlichen} {Neuronalen} {Netzen}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964054045&partnerID=40&md5=b2eff8f2df768ce1568ea54f44ed3cdb},
	abstract = {The Finite Element Method is a very powerful tool to enhance product quality and to reduce unnecessary and costly iterations during the product development process. However numerous errors can occur during the FE simulation. A promising way to realize precise and quick FE simulations is the comparison of the FE solution with analytical machine elements equations. This is only possible if the components in an assembly can be identified automatically. A promising way is to use the presented approach in this paper for part recognition with artificial neural networks and the use of detection surfaces.},
	author = {Spruegel, T.C. and Wartzack, S.},
	year = {2014},
	keywords = {abstract ok, Automatic Detection, FE software, FE-simulation, Finite element method, Machine element, Neural networks, Product development process},
	pages = {47--56},
}

@article{yan_functional-commercial_2011,
	title = {A functional-commercial analysis strategy for product conceptualization},
	volume = {38},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79953688214&doi=10.1016%2fj.eswa.2011.02.041&partnerID=40&md5=803bbc547fd21b3fa05b5339ed1b7129},
	doi = {10.1016/j.eswa.2011.02.041},
	abstract = {A functional-commercial analysis strategy is proposed to facilitate product conceptualization. General sorting is adopted to elicit initial product platform and generate initial design options. Designers' importance ratings are gathered and used to deal with cost- and time-related concerns. The restricted coulomb energy neural network is used for classifying and selecting design options. A case study on wood golf club design is conducted to illustrate the proposed approach. © 2011 Published by Elsevier Ltd.},
	number = {8},
	journal = {Expert Systems with Applications},
	author = {Yan, W. and Chen, C.-H. and Chang, W.},
	year = {2011},
	keywords = {abstract ok, Design, Design option, General sorting, Golf clubs, Importance rating, Initial design, Neural networks, Product conceptualization, Product development, Product platforms, Repertory grids, Restricted coulomb energy neural network, Restricted Coulomb energy neural network},
	pages = {9879--9887},
}

@inproceedings{hao_reliability_2012,
	title = {Reliability analysis method based on surpport vector machines classification and adaptive sampling strategy},
	volume = {544},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867813765&doi=10.4028%2fwww.scientific.net%2fAMR.544.212&partnerID=40&md5=928d0e157f0605f27ccb4b1d98c51daa},
	doi = {10.4028/www.scientific.net/AMR.544.212},
	abstract = {For probabilistic design problems with implicit limit state functions encountered in practical application, it is difficult to perform reliability analysis due to the expensive computational cost. In this paper, a new reliability analysis method which applies support vector machine classification(SVM-C) and adaptive sampling strategy is proposed to improve the efficiency. The SVM-C constructs a model defining the boundary of failure regions which classifies samples as safe or failed using SVM-C, then this model is used to replace the true limit state function,thus reducing the computational cost. The adaptive sampling strategy is applied to select samples along the constraint boundaries. It can also improves the efficiency of the proposed method. In the end, a probability analysis example is presented to prove the feasible and efficient of the proposed method. © (2012) Trans Tech Publications, Switzerland.},
	author = {Hao, H. and Qiu, H. and Chen, Z. and Xiong, H.},
	year = {2012},
	keywords = {abstract ok, Adaptive sampling, Adaptive Sampling Strategy, Computational costs, Constraint boundaries, Limit state functions, Probabilistic design, Probability analysis, Product development, Reliability analysis, Reliability Analysis, Reliability analysis method, Support vector machine classification, Support Vector Machine Classification, Support vector machines, Vector machines},
	pages = {212--217},
}

@inproceedings{bo_research_2012,
	title = {Research on knowledge representation in choosing mechanical transmission type},
	volume = {215-216},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870546519&doi=10.4028%2fwww.scientific.net%2fAMM.215-216.1098&partnerID=40&md5=71a94feb7676ff9b309c8967743f00cc},
	doi = {10.4028/www.scientific.net/AMM.215-216.1098},
	abstract = {To tackle the knowledge representation problem in developing intelligent conceptual design system, a BP network based approach is proposed, in which the related knowledge regarded various mechanical transmissions can be acquired and represented with the trained weight and threshold of neural network if they are turned into numerical data, encoded with binary strings, employed as learning samples, and fed into the constructed BP neural network. In a sense, the trained neural network can be used as a knowledge base of expert system to facilitate the choosing process of mechanical transmission. This paper provides a promising approach to deal with the automation of knowledge representation in conceptual design of mechanical transmission. © (2012) Trans Tech Publications, Switzerland.},
	author = {Bo, R. and Li, R. and Shen, X.},
	year = {2012},
	keywords = {abstract ok, Binary string, BP networks, BP neural networks, Concept design, Concept designs, Conceptual design, Conceptual design system, Digital storage, Expert systems, Knowledge base, Knowledge representation, Learning samples, Mechanical drive, Mechanical drives, Mechanical transmission, Neural network, Neural networks, Numerical data, Trained neural networks, Transmissions},
	pages = {1098--1101},
}

@article{chu_ann-based_2009,
	title = {{ANN}-based {3D} part search with different levels of detail ({LOD}) in negative feature decomposition},
	volume = {36},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-67349249738&doi=10.1016%2fj.eswa.2009.02.011&partnerID=40&md5=4f5c0f18fdca49f6bc3ca6735f7e7e2b},
	doi = {10.1016/j.eswa.2009.02.011},
	abstract = {Duplicate designs consume a large amount of enterprise resources during product development. Automatic search for similar parts is an effective solution for design reuse. Previous studies have only concerned similarity assessment based on complete 3D models, which may produce unsatisfactory result in practice. This paper proposes a novel scheme which incorporates the concept of LOD (levels of detail) into 3D part search. The scheme allows searching with different LOD variants created from the negative feature tree (NFT) of a solid model. A back-propagation artificial neural network is established to combine the D2-based similarity evaluation at each level of NFT. A human cognition model (HCM) is obtained by training the network with a set of data generated from a human experiment of similarity ranking. Search examples based on HCM show that the proposed scheme provides a practical tool for retrieval of similar part models. © 2009 Elsevier Ltd. All rights reserved.},
	number = {8},
	journal = {Expert Systems with Applications},
	author = {Chu, C.-H. and Cheng, H.-C. and Wang, E. and Kim, Y.-S.},
	year = {2009},
	keywords = {abstract ok, Backpropagation, Design, Design retrieval, Feature recognition, Levels of detail (LOD), Negative feature, Neural networks, Part search, Product development, Project management, Similarity assessment, Three dimensional},
	pages = {10905--10913},
}

@article{yu_fuzzy_2008,
	title = {A fuzzy intelligent design retrieving system for customer requirements},
	volume = {33},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-57649165202&doi=10.1504%2fIJCAT.2008.021947&partnerID=40&md5=8007a7ea6b5c963f45c1aadb848365b5},
	doi = {10.1504/IJCAT.2008.021947},
	abstract = {In the conceptual design stage of developing new products, the utilisation of the existing designs can significantly reduce design time and cost. This paper proposes a fuzzy intelligent design retrieving system to provide design engineers with easy access to relevant designs and knowledge. It employs fuzzy ARTMAP (FAM) neural network as its key technique to retrieve reference designs based on Customer Requirements (CRs) and Product Specifications (PSs). FAM learns from historical transaction, records. For newly emerging CRs, the system is able to retrieve reference designs that have similar PSs. By adjusting a single vigilance parameter, designers can retrieve a proper number of reference designs. Furthermore, it can create new groups of designs when new CRs fail to match any current grouping instances. Our implementation example shows that the proposed system is effective for retrieving designs in the conceptual design stage. Copyright © 2008 Inderscience Enterprises Ltd.},
	number = {2-3},
	journal = {International Journal of Computer Applications in Technology},
	author = {Yu, L. and Wang, L.},
	year = {2008},
	keywords = {abstract ok, Chromium, Conceptual design, Conceptual design stages, CR, Customer requirement, Customer requirements, Design engineers, Design retrieving system, Fuzzy ARTMAP, Fuzzy neural networks, Intelligent designs, Phosphorus, Product design, Product specification, Product specifications, PS, Reference designs, Sales, Specifications, Vigilance parameter},
	pages = {247--254},
}

@article{balakrishna_computer_2007,
	title = {Computer aided material selection processes in concurrent engineering using neural networks},
	volume = {88},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-41849087010&partnerID=40&md5=76d5fe769767bd5580e04e93c7f81898},
	abstract = {Selection of the proper materials for a structural component is critical to engineering design. Existing design procedures may currently be sufficient, especially where experience exists, but fierce industrial competition is spurring the search for improved methods and tools. The main drivers are quality, life-cycle cost and time-to-market. Improved design efficiency and accuracy may have an enormous impact on the economic viability of the final product. This paper discusses the materials selection processes in the context of structural design of under water vehicle propulsor rotor blade using neural networks. The use of computer-aided systems could assist designer and it will be potentially reduced product cost and timeto -market. Comp uter-aided systems for ma terials selection could assist concurren t engineering activities by helping to resolve many of the materials dilemmas presented during the initial design phase and by helping to guide the selection process based on the data as well as experience compiled from the previous product development.},
	number = {OCT.},
	journal = {Journal of the Institution of Engineers (India): Mechanical Engineering Division},
	author = {Balakrishna, A. and Rao, D.N. and Srinivas, J. and Satish, P.},
	year = {2007},
	keywords = {abstract ok, Approximation algorithms, Backpropagation algorithm, Backpropagation algorithms, Competition, Computer aided material selection, Concurrent engineering, Concurrent engineering functional approximation, Material ID, Material properties, Materials properties, Materials science, Neural networks},
	pages = {20--23},
}

@inproceedings{fu_recognizing_2009,
	title = {Recognizing network-like hand-drawn sketches- {A} convolutional neural network approach},
	volume = {5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-82155175313&doi=10.1115%2fDETC2009-87402&partnerID=40&md5=1f05567030684d0f3f6e0b9bb8fab59a},
	doi = {10.1115/DETC2009-87402},
	abstract = {Hand-drawn sketches are powerful cognitive devices for the efficient exploration, visualization and communication of emerging ideas in engineering design. It is desirable that CAD/CAE tools be able to recognize the back-of-the-envelope sketches and extract the intended engineering models. Yet this is a nontrivial task for freehand sketches. Here we present a novel, neural network-based approach designed for the recognition of network-like sketches. Our approach leverages a trainable, detector/ recognizer and an autonomous procedure for the generation of training samples. Prior to deployment, a Convolutional Neural Network is trained on a few labeled prototypical sketches and learns the definitions of the visual objects. When deployed, the trained network scans the input sketch at different resolutions with a fixed-size sliding window, detects instances of defined symbols and outputs an engineering model. We demonstrate the effectiveness of the proposed approach in different engineering domains with different types of sketching inputs. Copyright © 2009 by ASME.},
	author = {Fu, L. and Kara, L.B.},
	year = {2009},
	note = {Issue: PARTS A AND B},
	keywords = {abstract ok, CAD/CAE, Computer aided design, Convolution, Convolutional neural network, Design, Drawing (graphics), Engineering design, Engineering domains, Engineering models, Freehand sketch, Hand-drawn sketches, Models, Network-based approach, Neural networks, Non-trivial tasks, Sliding Window, Training sample, Visual objects, Visualization},
	pages = {671--681},
}

@inproceedings{zhang_product-form_2006,
	title = {A product-form aesthetic evaluation system},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-51249107368&doi=10.1109%2fCAIDCD.2006.329441&partnerID=40&md5=8f26b3c09da5c0f9bf8154caac13d209},
	doi = {10.1109/CAIDCD.2006.329441},
	abstract = {An artificial neural network-based aesthetic evaluation system for product-form is presented in this paper. Fuzzy set theory and semantic difference (SD) method are applied to set up an aesthetic evaluation experiment, in which 400 product images were evaluated. First, a database of normalized images and quantitative aesthetic descriptions was constructed. Second, a back-propagation (BP) network model was constructed to learn the relationship between image spaces and quantified aesthetic words. Last, an intelligent evaluation system for product design was then developed based on the learned BP model. Applications demonstrated that the system evaluate product form-aesthetics accurately. Designers may promptly modify their design with the guidance of evaluation.},
	author = {Zhang, Q. and Lu, C. and Wu, T. and Yu, S.},
	year = {2006},
	keywords = {abstract ok, Aesthetic evaluation, Artificial neural network (ANN), Computer networks, Conceptual design, Design, Fuzzy sets, Image, Image enhancement, Industrial engineering, Information theory, Neural networks, Product design, Product form, Semantic, Set theory},
}

@article{chen_investigation_2006,
	title = {An investigation into affective design using sorting technique and {Kohonen} self-organising map},
	volume = {37},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-31044456823&doi=10.1016%2fj.advengsoft.2005.07.001&partnerID=40&md5=998d9a41a789d6528269506bf2f0db2c},
	doi = {10.1016/j.advengsoft.2005.07.001},
	abstract = {In this paper, a prototype system that focuses on affective design perspective for iterative product concept development is proposed and described. The prototype system, which emphasises the solicitation of affective attributes from customers, employs a sorting technique, i.e. picture sorts, for acquiring customer's affective requirements and a hierarchical structure for representing designer's formal elements to meet customer's affective requirements in product conceptualisation. As hierarchical structure alone contains qualitative and uncertain inherence, a self-organised algorithm known as Kohonen self-organising map (SOM) neural network is employed to consolidate the relationship between affective requirements from customers and formal elements from designers so as to formulate a customer-oriented product concept. The performance of the prototype system is illustrated by using a case study on the design of a mobile hand phone. © 2005 Elsevier Ltd. All rights reserved.},
	number = {5},
	journal = {Advances in Engineering Software},
	author = {Chen, C.-H. and Khoo, L.P. and Yan, W.},
	year = {2006},
	keywords = {abstract ok, Affective design, Computer aided design, Customer affection hierarchy, Designer attribute hierarchy, Hierarchical systems, Learning algorithms, Neural networks, Product concept development, Product development, Self organizing maps, Self-organising map neural network, Software prototyping, Sorting, Sorting techniques},
	pages = {334--349},
}

@article{tsai_two-stage_2005,
	title = {A two-stage fuzzy approach to feature-based design retrieval},
	volume = {56},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-18844418226&doi=10.1016%2fj.compind.2005.02.001&partnerID=40&md5=9730378abf9f4d095678dc77d94727f8},
	doi = {10.1016/j.compind.2005.02.001},
	abstract = {In the conceptual design stage, designers usually begin the design process by referencing previous design cases similar to the one they are currently working on. Reviewing similar design cases can inspire a new idea and also shorten the design lead-time. To enhance this need, a two-stage fuzzy approach to feature-based design retrieval is developed in this research. First, a Fuzzy ART network is developed to search for designs based on geometric similarity. By adjusting a Fuzzy ART network parameter, designers can control the similarity of retrieved reference designs. Second, a fuzzy evaluation procedure is developed for finding reference designs with similar technological specifications. This procedure is capable of dealing with qualitative and quantitative technological attribute data. Implementation examples show the robustness of the proposed system in that it can flexibly retrieve reference designs based on geometric features and technological attributes even when incomplete query is provided. © 2005 Elsevier B.V. All rights reserved.},
	number = {5},
	journal = {Computers in Industry},
	author = {Tsai, C.-Y. and Chang, C.A.},
	year = {2005},
	keywords = {abstract ok, Data reduction, Design retrieval, Feature extraction, Feature-based design, Fuzzy ART network, Fuzzy searching, Fuzzy sets, Information retrieval, Neural networks, Parameter estimation, Set theory, Systems analysis},
	pages = {493--505},
}

@inproceedings{nurizada_sketch-based_2021,
	title = {Sketch-{Based} {Mechanism} {Simulation} {Using} {Machine} {Learning}},
	url = {https://dx.doi.org/10.1115/DETC2021-72149},
	doi = {10.1115/DETC2021-72149},
	abstract = {Abstract. This paper presents a machine learning approach for building an object detector for interactive simulation of planar linkages from handmade sketches and drawings found in patents and texts. Touch- and pen-input devices and interfaces have made sketching a more natural way for designers to express their ideas, especially during early design stages, but sketching existing complex mechanisms can be tedious and error-prone. While there are software applications available to help users make drawings, including that of a linkage mechanism, it is both educational and instructive to see existing sketches come to life via automated simulation. However, texts and patents present rich and diverse styles of mechanism drawings, which makes automated recognition difficult. Modern machine learning algorithms for object recognition require an extensive number of training images. However, there are no data sets of planar linkages available online. Therefore, our first goal was to generate images of sketches similar to hand-drawn ones and use state-of-the-art deep generation models, such as β-VAE, to produce more training data from a limited set of images. The latent space of β-VAE was explored by linear and spherical interpolations between sub-spaces and by varying latent space’s dimensions. This served two-fold objectives — 1) examine the possibility of generating new synthesized images via interpolation and 2) develop insights in the dependence of latent space dimension on bar linkage parameters. t-SNE dimensionality reduction technique was implemented to visualize the latent space of a β-VAE in a 2D space. Training images produced by animation rendering were used for fine-tuning a real-time object detection system — YOLOv3.},
	language = {en},
	urldate = {2025-03-05},
	publisher = {American Society of Mechanical Engineers Digital Collection},
	author = {Nurizada, Anar and Purwar, Anurag},
	month = nov,
	year = {2021},
	keywords = {abstract ok},
}

@article{nurizada_transforming_2023,
	title = {Transforming {Hand}-{Drawn} {Sketches} of {Linkage} {Mechanisms} {Into} {Their} {Digital} {Representation}},
	volume = {24},
	issn = {1530-9827},
	url = {https://doi.org/10.1115/1.4064037},
	doi = {10.1115/1.4064037},
	abstract = {This paper introduces a new method using deep neural networks for the interactive digital transformation and simulation of n-bar planar linkages, which consist of revolute and prismatic joints, based on hand-drawn sketches. Instead of relying solely on computer vision, our approach combines topological knowledge of linkage mechanisms with the outcomes of a convolutional deep neural network. This creates a framework for recognizing hand-drawn sketches. We generate a dataset of synthetic images that resemble hand-drawn sketches of linkage mechanisms. Next, we fine-tune a state-of-the-art deep neural network to detect discrete objects using building blocks that represent joints and links in various positions, sizes, and orientations within these sketches. We then conduct a topological analysis on the detected objects to construct a kinematic model of the sketched mechanisms. The results demonstrate the effectiveness of our algorithm in handling hand-drawn sketches and converting them into digital representations. This has practical implications for improving communication, analysis, organization, and classification of planar mechanisms.},
	number = {011010},
	urldate = {2025-03-05},
	journal = {Journal of Computing and Information Science in Engineering},
	author = {Nurizada, Anar and Purwar, Anurag},
	month = nov,
	year = {2023},
	keywords = {abstract ok},
	file = {Full Text PDF:C\:\\Users\\Sontag\\Zotero\\storage\\9GC4G6YD\\Nurizada und Purwar - 2023 - Transforming Hand-Drawn Sketches of Linkage Mechan.pdf:application/pdf},
}

@article{zuo_patent-kg_2022,
	title = {Patent-{KG}: {Patent} {Knowledge} {Graph} {Extraction} for {Engineering} {Design}},
	volume = {2},
	issn = {2732-527X},
	shorttitle = {Patent-{KG}},
	url = {https://www.cambridge.org/core/journals/proceedings-of-the-design-society/article/patentkg-patent-knowledge-graph-extraction-for-engineering-design/20ED39CC960546721682CEC91D6C8059},
	doi = {10.1017/pds.2022.84},
	abstract = {This paper builds a patent-based knowledge graph, patent-KG, to represent the knowledge facts in patents for engineering design. The arising patent-KG approach proposes a new unsupervised mechanism to extract knowledge facts in a patent, by searching the attention graph in language models. The extracted entities are compared with other benchmarks in the criteria of recall rate. The result reaches the highest 0.8 recall rate in the standard list of mechanical engineering related technical terms, which means the highest coverage of engineering words.},
	language = {en},
	urldate = {2025-03-05},
	journal = {Proceedings of the Design Society},
	author = {Zuo, H. and Yin, Y. and Childs, P.},
	month = may,
	year = {2022},
	keywords = {data-driven design, knowledge representations, artificial intelligence (AI), abstract ok},
	pages = {821--830},
	file = {Full Text PDF:C\:\\Users\\Sontag\\Zotero\\storage\\QIU5UIGK\\Zuo et al. - 2022 - Patent-KG Patent Knowledge Graph Extraction for E.pdf:application/pdf},
}

@article{wang_naive_2015,
	title = {A {Naïve} {Bayes} approach to map customer requirements to product variants},
	volume = {26},
	issn = {1572-8145},
	url = {https://doi.org/10.1007/s10845-013-0806-2},
	doi = {10.1007/s10845-013-0806-2},
	abstract = {A company develops product positioning strategy to make each product cover certain market segmentation and meet a group of customers’ requirements. In this sense, customer requirements can be mapped to a product variant. This paper addresses the issue of mapping customer requirements to existing product offerings. We treat the mapping task as a classification problem. Product variants are used as the class label for customer requirements. Considering that customer requirements are usually expressed in ambiguous language and contain uncertain information, a probabilistic Naïve Bayes based classifier is built by using existing customer choices data. The classifier takes new customer requirements as input and the output is the product variant which the customer may be satisfied with. In addition, the probabilistic classifier leverages on the flexibility of customer requirements and classifies the requirements based on the probability of relevance of each product variant. Case study shows that the approach can achieve good performance in terms of classification accuracy and F-measure.},
	language = {en},
	number = {3},
	urldate = {2025-03-05},
	journal = {Journal of Intelligent Manufacturing},
	author = {Wang, Yue and Tseng, Mitchell M.},
	month = jun,
	year = {2015},
	keywords = {Product design, Customer requirements, Mapping, Product positioning, Classification accuracy, Market segmentation, Sales, Classification (of information), Uncertain informations, Product variants, Naïve Bayes, abstract ok, Probabilistic classifiers, Product offerings},
	pages = {501--509},
	file = {Full Text PDF:C\:\\Users\\Sontag\\Zotero\\storage\\N978RRTI\\Wang und Tseng - 2015 - A Naïve Bayes approach to map customer requirement.pdf:application/pdf},
}

@inproceedings{paramasivan_comparing_2024,
	title = {Comparing {Supervised} and {Unsupervised} {Learning} {Technologies} for {Customer} {Segmentation} in {Marketing}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198829802&doi=10.1109%2fICONSTEM60960.2024.10568702&partnerID=40&md5=7f2989fb25a5bfd2533ffdb68491d7a0},
	doi = {10.1109/ICONSTEM60960.2024.10568702},
	abstract = {This study delves into the marketing practice of client segmentation by use of supervised and unsupervised learning tools. We investigate the efficacy of these two diverse methods and the ramifications they have in practice. We use supervised models like Random Forest and Support Vector Machine, as well as unsupervised clustering techniques like K-Means and Hierarchical Clustering, to conduct a hypothetical study on a dataset of 1,000 consumers. The results show the benefits and drawbacks of both methods, with supervised learning's accuracy in client segmentation being highlighted, and unsupervised learning's adaptability. This contrast shows how crucial it is to tailor your research approach to achieve your unique marketing goals. Implications for precise targeting, flexibility, and resource optimization in marketing tactics are also highlighted in the debate. This study helps to bridge the gap between machine learning theory and marketing practice, paving the way for better company results and happier customers. This study lays the groundwork for using machine learning strategically in consumer segmentation, which will become more important as the marketing environment develops in the future.  © 2024 IEEE.},
	author = {Paramasivan, C. and Paul Dhinakaran, D. and Selvam, S.S.P. and Mukherjee, S. and Juliet, A.P. and Devi, S.R.},
	year = {2024},
	keywords = {Machine Learning, Random Forest, Support vector machines, K-Means, K-means, Unsupervised learning, Machine-learning, Hierarchical Clustering, Forestry, Sales, Data driven, K-means clustering, Unsupervised Learning, Random forests, Support Vector Machine, Learning systems, Optimisations, Commerce, Hier-archical clustering, Support vectors machine, Customers segmentations, Customer Segmentation, abstract ok, Data-driven marketing, Data-driven Marketing, Marketing optimization, Marketing Optimization},
}

@inproceedings{nagaraj_customer_2023,
	title = {Customer {Segmentation} {Using} {Supervised} and {Unsupervised} {Machine} {Learning} {Techniques}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187780576&doi=10.1109%2fICDSAAI59313.2023.10452643&partnerID=40&md5=acc785b0f2e102c91048598eea6991cd},
	doi = {10.1109/ICDSAAI59313.2023.10452643},
	abstract = {Customer segmentation is an important method for any business and startup to understand the behaviour of the customers. It helps provide targeted marketing and service strategies. This method mainly divides the customers based on age, gender, behaviour, geography, and purchasing behaviour. By using this method, we can tailor our marketing campaigns. Machine learning is a powerful tool for customer segmentation. It can analyze historical data and identify patterns that cannot be found manually. This project aims to develop a machine-learning model for customer segmentation. The input of our project is historical data. The second step is to pre-process the data to ensure the quality of the data. The third step is to divide the data into two parts: train data and test data. The train data will be eighty percent, and the test data will be 20 percent. Then machine learning algorithms like k means clustering and Navy Bayes are trained on the train data to divide the customers into groups. After training the data is completed, and it is evaluated with the help of evaluation methods. With the help of this project, one can easily segment their customers and can build customized strategies for every segmentation of customers. The main aim of companies is to organize customers and provide efficient services for every segment. It can be attained by our project in a very efficient way. © 2023 IEEE.},
	author = {Nagaraj, P. and Bharath Kumar, C. and Kumar, K.C. and Venu, B. and Sekar, R.R. and Rajkumar, T.D.},
	year = {2023},
	keywords = {Machine Learning, Machine learning, Clustering, Data analytics, Ensemble learning, Data Analytics, Segmentation, Machine-learning, Sales, K-means clustering, Learning systems, Learning algorithms, Commerce, Clusterings, Historical data, Test data, Customers segmentations, Naïve Bayes, abstract ok, Naive bayes, Seaborn},
}

@inproceedings{mehboob_classification_2024,
	title = {Classification of {Customers} {Based} on {Classifications} of their {Category} {Using} {Machine} {Learning}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191144160&doi=10.1109%2fIC2PCT60090.2024.10486666&partnerID=40&md5=e9b112f60aa5289d5e3c33041b6beaa7},
	doi = {10.1109/IC2PCT60090.2024.10486666},
	abstract = {In today's data-driven business world, it is essential for companies trying to gain a competitive edge to understand customer behavior. Customer analysis and segmentation are crucial for customizing goods, services, and marketing strategies to meet varied client wants. In addition to agglomerative segmentation techniques, the proposed unique approach model MRFT examined the largest dataset of e-commerce which is being introduced by Gaussian, K-means, and DBSCAN clustering method. This study uses cutting-edge machine learning techniques, specifically classification algorithms, to assess and categorize customer data into distinct groups. By using the capabilities of algorithms like Random Forest, Support Vector Machines, this research aims to provide businesses with a comprehensive framework for maximizing client targeting and customization methods. The study's conclusions might increase customer satisfaction, increase revenue, and entice loyal customers. The study also looks at the potential, difficulties, and uses of machine learning for real-world customer segmentation applications.  © 2024 IEEE.},
	author = {Mehboob, S.S. and Niharika, T. and Guntapalli, K. and Suchindhra Prasad, K.D.M. and Parveen, N. and Anitha, R.},
	year = {2024},
	keywords = {Support vector machine, Customer satisfaction, Cluster analysis, Support vector machines, K-means, Random forest, Sales, K-means clustering, Customer segmentation, Random forests, k-means, Learning systems, Support vectors machine, Gaussians, Customer-centric, Customers segmentations, abstract ok, Customer centric approach, Customer centric Approach, Gaussian, Monetary, Recency, Segment interpretation, Segment Interpretation, Support vector machines (SVM)},
	pages = {1313--1318},
}

@inproceedings{ojha_hscrd_2022,
	title = {{HSCRD}: {Hybridized} {Semantic} {Approach} for {Knowledge} {Centric} {Requirement} {Discovery}},
	volume = {455 LNNS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130342743&doi=10.1007%2f978-3-031-02447-4_8&partnerID=40&md5=663000dba42931aec507fee15a10b105},
	doi = {10.1007/978-3-031-02447-4_8},
	abstract = {There is a necessity for a requirement recommendation system that can eliminate the old tedious recommendation discovery process. In this paper, a hybrid semantic approach for knowledge-centric requirement discovery has been proposed. The proposed HSCRD framework takes stakeholders’ interactions and preprocesses it. The individual keywords obtained are input into the TF-IDF model to yield the documents from the Requirement Specification Document Repository. The index words of these documents are extracted and are linked with Upper Domain Ontologies. The ontologies are grown by computing the semantic similarity measures, namely, Jaccard similarity and SemantoSim similarity. These grown ontologies are submitted to the Wikidata API, Freebase API, and DBPedia API to yield the Enriched Domain Ontologies. The Enriched Domain Ontologies, as features, are passed into Bi-gram and Tri-gram models. Using Bi-gram and Tri-gram of these features, input is given to the Bagging model for classification. Bagging is chosen with SVM and a highly complex Decision Tree classifier. Finally, the recommended documents and ontologies features are passed individually with respect to the classified documents through TF-IDF and semantic similarity pipeline in order to recommend the individual requirements. The proposed HSCRD achieves the highest average Accuracy with the Precision of 93.18\%, Recall of 95.69\%, Accuracy of 94.43\%, F-Measure of 94.42\%, a low FDR of 0.07, and a very high nDCG of 0.96. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author = {Ojha, R. and Deepak, G.},
	year = {2022},
	keywords = {Ontologies, Semantic similarity, Requirement engineering, abstract ok, Requirement discovery},
	pages = {70--79},
}

@inproceedings{li_mining_2007,
	title = {Mining customer preferences with {ANN}-{DT}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-38049025361&doi=10.1109%2fWICOM.2007.1343&partnerID=40&md5=1c31ab2af453983c9055f9b139328a39},
	doi = {10.1109/WICOM.2007.1343},
	abstract = {In the early stage of product design, mining customer preference is the key issue to the development of satisfactory products. This paper builds a preference model from a set of historical transaction to catch what customer wants in mass customization. An artificial neural-network decision tree algorithm (ANN-DT) is employed to model customer preference on different product families. It is able to extract with rules of customer preference with high fidelity. To illustrate the effectiveness of the proposed method, a case study of personal computers is reported. © 2007 IEEE.},
	author = {Li, Y. and Liya, W.},
	year = {2007},
	keywords = {Neural networks, Customer satisfaction, Customer preference, Algorithms, Product design, Decision trees, Mass customization, Personal computers, abstract ok, ANN-DT},
	pages = {5479--5482},
}

@article{shil_evaluating_2007,
	title = {Evaluating product plans using real options},
	volume = {52},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34648840513&doi=10.1080%2f00137910701504058&partnerID=40&md5=536127c30cf308be4fc91154963a211f},
	doi = {10.1080/00137910701504058},
	abstract = {Product planning helps a company to strategically plan its current and future product platforms and offer product variants in the marketplace. Product platforming is widely touted as a successful strategy for mass customization. However, due diligence should be exercised before implementing any product platform strategy. The product planning exercise should account for future uncertainties. Traditional financial tools such as the net present value (NPV) are static since they do not compensate for any exogenous and endogenous uncertainties during the course of the project. The crux of the problem lies in the evaluation model that is used for evaluating the product planning projects. While many view uncertainties in a product planning project as problematic, it can also be viewed as a source of new opportunities. We argue that uncertainties should be an integral part of the evaluation model. If the future possibilities (or strategic options) are not considered in the evaluation model, a corporation may face a "myopic syndrome". In this article, we consider two important product planning decisions - platform decisions and product variant decisions. The platform decision involves strategic selection of a concept product platform from various possible alternative concept product platforms. The product variant decision involves deciding how long a company should continue to offer its current product variant in the marketplace and whether the existing product variant should be discontinued, scaled down, or scaled up with additional product features. To address the two aforementioned decisions, we developed a real options-based methodology that considers technical, project implementation, and market-related uncertainties. The proposed methodology uses a binomial and quadranomial lattice approach to build a decision tree. Product planning decisions at various decision tree nodes are evaluated using a risk-neutral option valuation methodology. We demonstrate the working of the proposed methodology using an illustrative example.},
	number = {3},
	journal = {Engineering Economist},
	author = {Shil, P. and Allada, V.},
	year = {2007},
	keywords = {Product development, Product planning, Decision trees, Uncertainty analysis, Mass customization, Strategic planning, Product variants, Value engineering, abstract ok},
	pages = {215--253},
}

@inproceedings{jiao_mapping_2017,
	title = {Mapping {High} {Dimensional} {Sparse} {Customer} {Requirements} into {Product} {Configurations}},
	volume = {261},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035132505&doi=10.1088%2f1757-899X%2f261%2f1%2f012022&partnerID=40&md5=b5cbe80806238a5a088ed51de3c7bf04},
	doi = {10.1088/1757-899X/261/1/012022},
	abstract = {Mapping customer requirements into product configurations is a crucial step for product design, while, customers express their needs ambiguously and locally due to the lack of domain knowledge. Thus the data mining process of customer requirements might result in fragmental information with high dimensional sparsity, leading the mapping procedure risk uncertainty and complexity. The Expert Judgment is widely applied against that background since there is no formal requirements for systematic or structural data. However, there are concerns on the repeatability and bias for Expert Judgment. In this study, an integrated method by adjusted Local Linear Embedding (LLE) and Naïve Bayes (NB) classifier is proposed to map high dimensional sparse customer requirements to product configurations. The integrated method adjusts classical LLE to preprocess high dimensional sparse dataset to satisfy the prerequisite of NB for classifying different customer requirements to corresponding product configurations. Compared with Expert Judgment, the adjusted LLE with NB performs much better in a real-world Tablet PC design case both in accuracy and robustness. © Published under licence by IOP Publishing Ltd.},
	author = {Jiao, Y. and Yang, Y. and Zhang, H.},
	year = {2017},
	note = {Issue: 1},
	keywords = {abstract ok, Artificial intelligence, Barium compounds, Classification (of information), Customer requirements, Customer satisfaction, Data mining, Data mining process, Domain knowledge, High-dimensional, Integrated control, Integrated method, Local Linear Embedding, Mapping, Personal computers, Product configuration, Product design, Sales, Sodium compounds, Uncertainty and complexity},
}

@inproceedings{nakatani_toward_2012,
	title = {Toward the decision tree for inferring requirements maturation types},
	volume = {E95-D},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859368215&doi=10.1587%2ftransinf.E95.D.1021&partnerID=40&md5=1689c2154c2bd549e06e73ef7d770c80},
	doi = {10.1587/transinf.E95.D.1021},
	abstract = {Requirements are elicited step by step during the requirements engineering (RE) process. However, some types of requirements are elicited completely after the scheduled requirements elicitation process is finished. Such a situation is regarded as problematic situation. In our study, the difficulties of eliciting various kinds of requirements is observed by components. We refer to the components as observation targets (OTs) and introduce the word "Requirements maturation:' It means when and how requirements are elicited completely in the project. The requirements maturation is discussed on physical and logical OTs. OTs Viewed from a logical viewpoint are called logical OTs, e.g. quality requirements. The requirements of physical OTs, e.g., modules, components, subsystems, etc., includes functional and non-functional requirements. They are influenced by their requesters' environmental changes, as well as developers' technical changes. In order to infer the requirements maturation period of each OT, we need to know how much these factors influence the OTs' requirements maturation. According to the observation of actual past projects, we defined the PRINCE (Pre Requirements Intelligence Net Consideration and Evaluation) model. It aims to guide developers in their observation of the requirements maturation of OTs. We quantitatively analyzed the actual cases with their requirements elicitation process and extracted essential factors that influence the requirements maturation. The results of interviews of project managers are analyzed by WEKA, a data mining system, from which the decision tree was derived. This paper introduces the PRINCE model and the category of logical OTs to be observed. The decision tree that helps developers infer the maturation type of an OT is also described. We evaluate the tree through real projects and discuss its ability to infer the requirements maturation types. Copyright © 2012 The Institute of Electronics, Information and Communication Engineers.},
	author = {Nakatani, T. and Kondo, N. and Shirogane, J. and Kaiya, H. and Hori, S. and Katamine, K.},
	year = {2012},
	note = {Issue: 4},
	keywords = {Data mining, Project management, Decision trees, Non-functional requirements, Quality requirements, Technology transfer, Requirements engineering, Trees (mathematics), Environmental change, abstract ok, Requirements change, Requirements elicitation, Observation targets, Requirements changes, Requirements maturation, Requirements process},
	pages = {1021--1030},
}

@inproceedings{dasbach_self-trained_2021,
	title = {Self-trained {CAD} assistance for constraining assemblies based on decision trees and support vector classification},
	volume = {104},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121601913&doi=10.1016%2fj.procir.2021.11.322&partnerID=40&md5=54afa302de6f937769c2ede8ff44524c},
	doi = {10.1016/j.procir.2021.11.322},
	abstract = {In this publication a concept for a self-trained assistance is presented, which places a part, selected by the designer, into an assembly and fixates it with constrains. Therefor all selectable parts are classified by the assistance beforehand. In the process of developing the classification several algorithm were tested and compared regarding speed and precision. To place and constrain the parts, decision trees for supervised learning were arranged in a multi-step structure. Furthermore, the implementation in the CAD environment Fusion 360 as well as the limitations and potentials of the concept are discussed. © 2021 The Author(s).},
	author = {Dasbach, T. and Lohr, R. and Muth, F. and Anderl, R.},
	year = {2021},
	keywords = {abstract ok, Assembly, CAD, Classifieds, Computer aided design, Decision trees, Decision Trees, Forestry, Machine learning, Machine Learning, Machine-learning, Multisteps, Static Var compensators, Step structure, Support vector classification, SVC},
	pages = {1907--1911},
}

@article{jiao_integration_2019,
	title = {An integration model for generating and selecting product configuration plans},
	volume = {30},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017630962&doi=10.1007%2fs10845-017-1324-4&partnerID=40&md5=1d7e4149ab91232b934e313c559db490},
	doi = {10.1007/s10845-017-1324-4},
	abstract = {In the developed market, time-to-market and market shares require companies to provide products that satisfy customer requirements in a timely manner, and the variety in product configurations has been analyzed thoroughly. Against this background, this study addresses an integration model for generating feasible configuration plans based on market transaction data and for selecting the optimal configuration plan(s) based on customer requirements. Transaction data can be used for clustering products to analyze the characteristics of segmented markets and yield the probabilities of configuration plans; along with the constraint conditions, feasible configuration plans can be generated, as well as market strategies for different segmented markets. In addition, a probabilistic classifier, the Naïve Bayes Classifier, is applied to map the customer requirements to the configuration plan with the highest probability. The classifier is suitable for handling imprecise and uncertain information, such as product requirements expressed by customers. A case study of a mouse device is illustrated, and the results indicate the integration model can achieve a good performance in terms of time advantages in project design. © 2017, Springer Science+Business Media New York.},
	number = {3},
	journal = {Journal of Intelligent Manufacturing},
	author = {Jiao, Y. and Yang, Y. and Zhang, H.},
	year = {2019},
	keywords = {abstract ok, Classification (of information), Commerce, Competition, Constraint conditions, Customer requirements, Customer satisfaction, Integration, Market strategies, Market strategy, Probabilistic classifiers, Product clustering, Product configuration, Product design, Product requirements, Sales, Uncertain informations},
	pages = {1291--1302},
}

@inproceedings{abad_what_2017,
	title = {What {Works} {Better}? {A} {Study} of {Classifying} {Requirements}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032825139&doi=10.1109%2fRE.2017.36&partnerID=40&md5=1a0038b42890663de6a1aec409206a91},
	doi = {10.1109/RE.2017.36},
	abstract = {Classifying requirements into functional requirements (FR) and non-functional ones (NFR) is an important task in requirements engineering. However, automated classification of requirements written in natural language is not straightforward, due to the variability of natural language and the absence of a controlled vocabulary. This paper investigates how automated classification of requirements into FR and NFR can be improved and how well several machine learning approaches work in this context. We contribute an approach for preprocessing requirements that standardizes and normalizes requirements before applying classification algorithms. Further, we report on how well several existing machine learning methods perform for automated classification of NFRs into sub-categories such as usability, availability, or performance. Our study is performed on 625 requirements provided by the OpenScience tera-PROMISE repository. We found that our preprocessing improved the performance of an existing classification method. We further found significant differences in the performance of approaches such as Latent Dirichlet Allocation, Biterm Topic Modeling, or Naïve Bayes for the sub-classification of NFRs. © 2017 IEEE.},
	author = {Abad, Z.S.H. and Karras, O. and Ghazi, P. and Glinz, M. and Ruhe, G. and Schneider, K.},
	year = {2017},
	keywords = {Artificial intelligence, Clustering, Automation, Naive Bayes, Statistics, Classification, Non-functional requirements, Requirements engineering, Latent Dirichlet allocation, Learning systems, Classification (of information), Machine learning methods, Machine learning approaches, Topic Modeling, Classification algorithm, abstract ok, Naive bayes, Functional and Non-Functional Requirements},
	pages = {496--501},
}

@article{mehta_approach_2012,
	title = {An approach to predict impact of proposed engineering change effect},
	volume = {12},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859067710&doi=10.1115%2f1.4005593&partnerID=40&md5=93bf043606a059d9d31198b657124a51},
	doi = {10.1115/1.4005593},
	abstract = {Detailed evaluation of a proposed engineering change (EC) or its effects is a time-consuming process requiring considerable user experience and expertise. Therefore, enterprises plan detailed evaluation of only those EC effects that might have a significant impact. Since similar ECs are likely to have similar effects and impacts, past EC knowledge can be utilized for determining whether the proposed EC effect has significant impact. This paper presents an approach for predicting the impact of proposed EC effect based on past ECs that are similar to it. Our approach accounts for the differences in context of impact between attribute values in two changes. The Bayes' rule is utilized to determine differences in impact value based on the differences in attribute values. The probability values required in Bayes' rule are determined based on the principle of minimum cross entropy. An example EC knowledge base is created and utilized to evaluate our approach against two state-of-the-art approaches, namely k-nearest neighbor (NN) and regularized local similarity discriminant analysis (SDA). The success rate in predicting impact is used as an evaluation metric. The results show that there is a statistically significant improvement in success rate obtained using our approach as compared to those obtained using the two state-of-the-art approaches. The results also show that for a very large number of proposed ECs, i.e., N {\textgreater} 100, the success rate in predicting impact using our approach shall be greater than that obtained using the two state-of-the-art approaches. © 2012 American Society of Mechanical Engineers.},
	number = {2},
	journal = {Journal of Computing and Information Science in Engineering},
	author = {Mehta, C. and Patil, L. and Dutta, D.},
	year = {2012},
	keywords = {abstract ok, Attribute values, Bayes' rule, Discriminant analysis, Engineering changes, Evaluation metrics, Forecasting, Impact value, K-nearest neighbors, Knowledge base, Knowledge based systems, Local similarity, Principle of minimum cross entropy, Significant impacts, State-of-the-art approach, User experience},
}

@article{wang_hybrid_2020,
	title = {A hybrid big data analytical approach for analyzing customer patterns through an integrated supply chain network},
	volume = {20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092923517&doi=10.1016%2fj.jii.2020.100177&partnerID=40&md5=ec9966ee6323887f288aa282acd2b37f},
	doi = {10.1016/j.jii.2020.100177},
	abstract = {The recent technology innovation such as big data and its applications has been adopted widely in industries in order to deal with massive datasets. Through data integration, data analysis, and data interpretation, big data technologies can assist business stakeholders in gaining the benefits in their decision-making process. In this research, we hypothesize that combining several big data analytical methods for analyzing integrated customer data can provide more effective and intelligent strategies. A hybrid model combining recency, frequency, and monetary value (RFM) model, K-means clustering, Naïve Baye's algorithm, and linked Bloom filters is proposed to target different customer segments. Our results suggest that (1) the use of big data analytics can provide marketers a direction to make marketing strategies; (2) the use of big data analytics can predict potential customer demands; and (3) the proposed linked Bloom filters can store inactive data in a more efficient way for future use. © 2020},
	journal = {Journal of Industrial Information Integration},
	author = {Wang, S.-C. and Tsai, Y.-T. and Ciou, Y.-S.},
	year = {2020},
	keywords = {Decision making, Big data analytics, K-means, Data Analytics, Supply chains, Data integration, Sales, K-means clustering, Customer segmentation, RFM, Decision making process, Large dataset, Data structures, Commerce, Data interpretation, Technology innovation, Marketing strategy, Advanced Analytics, Analytical approach, Potential customers, abstract ok, Bloom filters, Blooms (metal), Integrated supply chain networks, Intelligent strategies, Naïve Bayes’ algorithm},
}

@inproceedings{wei_approach_2009,
	title = {An approach of product configuration based on decision tree and minimum conflicts repair algorithm},
	volume = {1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77649329842&doi=10.1109%2fICIII.2009.37&partnerID=40&md5=64eb7e0884acca931a183e333c0307a9},
	doi = {10.1109/ICIII.2009.37},
	abstract = {This paper develops a new approach of product configuration incorporating methods of decision tree and minimum conflicts repair algorithm. Firstly, the product decision tree is developed for certain category of products, in which the descriptive and interpretative requirements are taken as constraints to cut the branches of the product decision tree in order to obtain the product family meeting the customer needs best. Secondly, the method of case based reasoning is applied to search the product case matching the customer needs in the specific product family. Finally, the minimum conflicts repair algorithm is adopted to adjust the product case to satisfy the configuration constraints, by which the adaptation of product can be finished independently. © 2009 IEEE.},
	author = {Wei, G. and Qin, Y.},
	year = {2009},
	keywords = {abstract ok, Algorithms, Case based reasoning, Case matching, Configuration constraints, Customer need, Decision tree, Decision trees, Industrial engineering, Information management, Innovation, Minimum conflicts repair algorithm, New approaches, Product configuration, Product families, Repair, Repair algorithms},
	pages = {126--129},
}

@article{li_design_2024,
	title = {Design of {Digital} {Visual} {Transmission} {System} {Based} on {CAD} {Aided} {Technology} and {Deep} {Learning}},
	volume = {21},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169031606&doi=10.14733%2fcadaps.2024.S1.146-160&partnerID=40&md5=c72defce7a0fe33a8c1941d919c9270d},
	doi = {10.14733/cadaps.2024.S1.146-160},
	abstract = {During the growth of AI (Artificial intelligence), DL (Deep learning) is a main research direction. This article deeply studies DL, and applies CAD technology and DL to the construction of digital visual transmission system. It constructs a neural network extraction optimization model based on image feature analysis. In the classification of image training models using network methods, deep learning is used to optimize image features. Improve the performance of DL network by optimizing model and parameters. Experimental research shows that the error of this algorithm is low, and the highest accuracy can reach 96.11\%. Moreover, in the case of large parallel operation, the stability can reach about 89\%, which shows that the system performance is excellent. Compared with the traditional decision tree algorithm, this method is more flexible, efficient, fast and practical. It provides theoretical and technical support for the application of CAD technology in the design of digital visual transmission system. © 2024, CAD Solutions, LLC. All rights reserved.},
	number = {S1},
	journal = {Computer-Aided Design and Applications},
	author = {Li, N.},
	year = {2024},
	keywords = {abstract ok, CAD Technologies, CAD Technology, Computer aided design, Convolutional neural network, Convolutional Neural Network, Convolutional neural networks, Decision trees, Deep learning, Deep Learning, E-learning, Engineering education, Extraction optimizations, Learning systems, Model-based OPC, Network extractions, Neural-networks, Optimization models, Transmission systems, Transmissions, Visual transmission, Visual Transmission},
	pages = {146--160},
}

@article{zhang_research_2022,
	title = {Research on the {Intelligent} {Design} of {Office} {Chair} {Patterns}},
	volume = {12},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125071374&doi=10.3390%2fapp12042124&partnerID=40&md5=d8d0a09f6b59229496689726be9210fc},
	doi = {10.3390/app12042124},
	abstract = {(1) Background: Personalized product customization is an important direction in the development of the chair industry. This paper studies an intelligent design method for the rapid realization of personalized office chair customization; (2) Methods: based on the case-based reasoning (CBR) method, the characteristic attributes of office chair patterns are analyzed, and an attribute model is established. According to office chair data and customer demand, an intelligent design model using multi-layer weighted k-nearest neighbor (K-NN) for chair patterns is developed using the entropy weight method and an analytic hierarchy process. In addition, an example is employed for verification of the K-NN and multi-layer weighted K-NN retrieval models; (3) Results: both models are able to effectively retrieve chair type cases that meet the target requirements from the office chair pattern base; the case matching similarity of the multi-layer weighted K-NN retrieval model was higher, with an average increase of about 3.9\%, and the chair pattern case results obtained by setting different customer needs are different, indicating that the case can be selected according to different customer preferences, which is more conducive to personalized product customization design; (4) Conclusions: The multi-layer weighted K-NN model for intelligent chair pattern design proposed in this paper is more conducive to personalized product customization design. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	number = {4},
	journal = {Applied Sciences (Switzerland)},
	author = {Zhang, J. and Yin, A. and Chen, G. and Li, Y. and Lu, Z. and Wang, B.},
	year = {2022},
	keywords = {abstract ok, Intelligent design, K-nearest neighbor, Office chair pattern},
}

@inproceedings{ferrero_using_2020,
	title = {Using decision trees supported by data mining to improve function-based design},
	volume = {11A-2020},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096340216&doi=10.1115%2fDETC2020-22498&partnerID=40&md5=bc70e5a058e0e994fbb1510ee62e3be5},
	doi = {10.1115/DETC2020-22498},
	abstract = {Engineering designers currently use downstream information about product and component functions to facilitate ideation and concept generation of analogous products. These processes, often called Function-Based Design, can be reliant on designer definitions of product function, which are inconsistent from designer to designer. In this paper, we employ supervised learning algorithms to reduce the variety of component functions that are available to designers in a design repository, thus enabling designers to focus their function-based design efforts on more accurate, reduced sets of potential functions. To do this, we generate decisions trees and rules that define the functions of components based on the identity of neighboring components. The resultant decision trees and rulesets reduce the number of feasible functions for components within a product, which is of particular interest for use by novice designers, as reducing the feasible functional space can help focus the design activities of the designer. This reduction was evident in both case studies: one exploring a component that is known to the designer, and the other looking at defining function of an unrecognizable component. The work presented here contributes to the recent popularity of using product data in data-driven design methodologies, especially those focused on supplementing designer cognition. Importantly, we found that this methodology is reliant on repository data quality, and the results indicate a need to continue the development of design repository data schemas with improved data consistency and fidelity. This research is a necessary precursor for the development of function-based design tools, including automated functional modeling. © 2020 American Society of Mechanical Engineers (ASME). All rights reserved.},
	author = {Ferrero, V.J. and Alqseer, N. and Tensa, M. and DuPont, B.},
	year = {2020},
	keywords = {abstract ok, Computer aided design, Concept generation, Data mining, Data-driven design, Decision trees, Design repository, Engineering designer, Forestry, Function-based design, Functional spaces, Learning algorithms, Potential function, Product design, Product functions, Trees (mathematics)},
}

@article{gu_layered_2021,
	title = {A layered {KNN}-{SVM} approach to predict missing values of functional requirements in product customization},
	volume = {11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103035714&doi=10.3390%2fapp11052420&partnerID=40&md5=bab8f986a821839443d918e445ff958e},
	doi = {10.3390/app11052420},
	abstract = {The conversion from functional requirements (FRs) to design parameters is the foundation of product customization. However, original customer needs usually result in incomplete FRs, limited by customers’ incomprehension on the design requirements of these products. As the incomplete FRs may undermine the design activities afterwards, managers need to develop an effective approach to predict the missing values of the FR. This study proposes an integrative approach to obtain the complete FR. The k nearest neighbor (KNN) algorithm is employed to predict the missing continuous variables in FR, using the improved distance formula for two incomplete FRs. Support vector machine (SVM) classifiers are adopted to classify the missing categorical variables in FR, combined with directed acyclic graph for multi-class classification. KNN and SVM are then integrated into a multi-layer framework to predict the missing values of FR, where categorical and continuous variables both exist. A case study on the elevator customization is conducted to verify that KNN-SVM is feasible in accurate prediction of elevator FR values. Furthermore, KNN-SVM outperforms other five single and five composite methods, with average reduction in root mean squared error (RMSE) of 39\% and 21\% against KNN and KNN-Tree, respectively. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	number = {5},
	journal = {Applied Sciences (Switzerland)},
	author = {Gu, Y. and Zhang, S. and Qiu, L. and Wang, Z. and Zhang, L.},
	year = {2021},
	keywords = {Product customization, Functional requirements, abstract ok, Categorical and continuous variables, KNN-SVM, Missing values prediction},
}

@inproceedings{ebel_automated_2021,
	title = {Automated measuring of engineering progress based on {ML} algorithms},
	volume = {99},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106439040&doi=10.1016%2fj.procir.2021.03.114&partnerID=40&md5=c71f2edc3c8303f41b19b8a33815dc32},
	doi = {10.1016/j.procir.2021.03.114},
	abstract = {A significant challenge of managing successful engineering projects is to know their status at any time. This paper describes the background of engineering projects' progress and presents an automated approach based on machine learning (ML) algorithms (e.g., KNN, random forest, and decision tree). The information required to measure engineering activities' progress is extracted from engineering artifacts and subsequently analyzed and interpreted concerning the project's progress. The approach integrates information from previous projects by considering historical data using ML algorithms and actual unfinished artifacts to determine the degree of completion. © 2021 The Authors. Published by Elsevier B.V.},
	author = {Ebel, H. and Stark, R. and Tsigkros, A.},
	year = {2021},
	keywords = {abstract ok, Automated approach, Automated measuring, CAD maturity, Computer aided design, Decision trees, Elsevier, Engineering project, Learning algorithms, Machine learning, Machine learning algorithms, Machine-learning, On-machines, Product maturity, Project progress},
	pages = {627--632},
}

@inproceedings{murugeswari_conceptual_2021,
	title = {Conceptual {Analysis} of {Product} {Evaluations} {Using} {Deep} {Learning}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104995254&doi=10.1109%2fICACITE51222.2021.9404565&partnerID=40&md5=5efabb04c915e4cabcb4b89bdd239f84},
	doi = {10.1109/ICACITE51222.2021.9404565},
	abstract = {The process of classifying a small text piece into positive, negative or neutral is called as Sentiment Analysis. For example, if a message is considered, then the meaning of the sentence is identified and then analysis of the sentence has to be done. After analysis, we decide that the sentence is either positive, either negative or neutral. This is referred to as Sentiment Analysis. Nowadays, most of the people prefer the online products compared to the direct buyers. So, the online marketing is growing very high. In fact, the online marketing is fully satisfying the customer needs so that it occupies a great place in people's heart. They are also satisfying the demands of customers with high quality and low price. These are the primary reasons for the online marketing to be in a successful position. If an e-commerce company has an ability to gather information about the customer thoughts and behavior, then the online marketing will be more effective than now. In this paper, we have taken a particular e-commerce dataset called Flipkart and classify the polarity of the comments by using some of the classifiers namely Support Vector Machine Classifier, Guassian Naïve Bayes Classifier and Random Forest Classifier and Multilayer Perceptron Classifier. The existing approach is that the comments were classified based on the attitude of the customer. But, now the proposed approach has been implemented with the help of Multilayer Perceptron (MLP) Neural Network Classifier which is simulated by the SPYDER tool. The accuracy for all the four algorithms namely, Support Vector Machine, Random Forest, Naïve Bayes and Multilayer Perceptron (MLP) Neural Network algorithm has been computed and the best accuracy has been predicted by comparing them. Here, the Multilayer Perceptron (MLP) shows the best accuracy of all others and the accuracy is 99.94\%. Moreover, some performance metrics has been determined here. The performance metrics namely Precision, Recall and F-measure has been evaluated for each algorithm individually and then the comparison is made among them. Then, the ROC curve is measured for the classes designated by us for revealing the recognition of parameters between two diagnostic groups. It is predicted individually for each class. At last, the Confusion Matrix is going to enumerate for each algorithm distinctly. It presents the actual and predicted values in a tabular format thereby measuring the performance of a classifier. © 2021 IEEE.},
	author = {Murugeswari, R. and Ramasakthi, G.},
	year = {2021},
	keywords = {Deep learning, Sentiment analysis, Support vector machines, Decision trees, Performance metrics, Electronic commerce, Sentiment Analysis, Sales, Multilayer neural networks, Product evaluation, Random forests, Multilayers, Multi layer perceptron, Taxonomies, Random forest classifier, Conceptual analysis, abstract ok, Support vector machine classifiers, Guassian NB Classifier, Multi-layer perceptron classifiers, Multilayer Perceptron Classifier, Multilayer perceptron neural networks, Product Reviews, Random Forest Classifier, SVM Classifier},
	pages = {820--825},
}

@article{wu_approach_2018,
	title = {An approach to discovering product/service improvement priorities: {Using} dynamic importance-performance analysis},
	volume = {10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054504767&doi=10.3390%2fsu10103564&partnerID=40&md5=da349e0ea536f2dbdf7473770b0d2442},
	doi = {10.3390/su10103564},
	abstract = {The cost budget and resources of a business are limited. In order to be competitive sustainably in the market, it is necessary for a businesses to discover the improvement priorities of their product/service features effectively and allocate their resources appropriately for higher customer satisfaction. Online customer review mining has been attracting increasing attention for businesses to discover priorities of product/service improvement from online customer reviews. Despite some prior related studies, their methods have several limitations, such as simply using the frequencies of mentioned product features in reviews as an indicator of importance; neglecting the market competition; and focusing only on the static importance and performance of the target product/service features. To address those limitations, this study proposes a novel approach to discovering a product/service's improvement priorities through dynamic importance-performance analysis of online customer reviews. It first clusters similar features into a feature group and calculate the relative performance of the feature groups using sentiment analysis. Next, the importance of each feature group's performance to overall customer satisfaction is measured by the factor categories based on the Kano's model. The factor categories are determined by the significance values of each feature group in both positive and negative sentiment polarities derived from the constructed decision tree. Finally, feature improvement priorities of a target product/service will be discovered based on the dynamic performance trend and predicted importance using a dynamic importance-performance analysis. The evaluation results show that the dynamic importance-performance analysis approach proposed in this study is a much better approach for product/service improvement priorities discovering than the product opportunity mining approach proposed in the prior studies. This study makes new research contributions to automatic discovery of product/service improvement priorities from large-scale online customer reviews. The proposed approach can also be used for product/service performance monitoring and customer needs analysis to improve product/service design and marketing campaigns. © 2018 by the authors.},
	number = {10},
	journal = {Sustainability (Switzerland)},
	author = {Wu, J. and Wang, Y. and Zhang, R. and Cai, J.},
	year = {2018},
	keywords = {Sentiment analysis, marketing, Online customer reviews, competitiveness, abstract ok, cost analysis, Importanceperformance analysis, Improvement priorities, market conditions, resource use},
}

@inproceedings{chen_3d_2013,
	title = {{3D} {CAD} model retrieval based on feature fusion},
	volume = {765-767},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885077386&doi=10.4028%2fwww.scientific.net%2fAMR.765-767.316&partnerID=40&md5=bf8e0c022f6238e3e75dd0984916aabc},
	doi = {10.4028/www.scientific.net/AMR.765-767.316},
	abstract = {Existing 3D model retrieval techniques focus on the global feature more than local detailed feature are not applicable to 3D CAD models. This paper combines the local feature and global feature to satisfy the needs of mechanical design. We first analyze the limitations of Shape Description (SD) algorithm. Then propose an automatic feature extraction technology based on the local characteristics of the curvature distribution. Next we fuse the extracted feature using a novel method. Lastly, we design an improved K-nearest neighbor algorithm to retrieve models. Experimental results indicate the efficiency and feasibility of the proposed method. © (2013) Trans Tech Publications, Switzerland.},
	author = {Chen, Q. and Yu, Y.M.},
	year = {2013},
	keywords = {3-d cads, 3D CAD retrieval, abstract ok, Computer aided design, Curvature distribution, Curvature distributions, Feature fusion, Image retrieval, Knn, Pattern recognition, Self organizing maps, Shape distribution, Three dimensional},
	pages = {316--319},
}

@article{li_evidence-based_2014,
	title = {Evidence-based {SVM} fusion for {3D} model retrieval},
	volume = {72},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904856846&doi=10.1007%2fs11042-013-1475-z&partnerID=40&md5=ecc91bf6112fb2ff8dcbf3080e869761},
	doi = {10.1007/s11042-013-1475-z},
	abstract = {Many existing 3D model retrieval use KNN (k-nearest neighbor) method for similarity search, but it is inefficient in high-dimension space search. In this paper, the classification tools are integrated for supporting more effective 3D model search in the high-dimensional feature space. Our proposed algorithm used multiple SVM classifiers to predict 3D models for a given query and D-S Evidence theory is used to fuse all the prediction results. Experimental results show that our proposed 3D model retrieval algorithm can improve the accuracy significantly compared with the traditional kNN method. © 2013 Springer Science+Business Media New York.},
	number = {2},
	journal = {Multimedia Tools and Applications},
	author = {Li, Z. and Wu, Z. and Kuang, Z. and Chen, K. and Gan, Y. and Fan, J.},
	year = {2014},
	keywords = {3D model retrieval, abstract ok, Classification, Classification (of information), Classification tool, Classifier fusion, D S evidence theory, Evidence theories, Evidence theory, High-dimensional feature space, K-nearest neighbors, Learning algorithms, Probabilistic logics, Similarity search},
	pages = {1731--1749},
}

@article{yu_identification_2008,
	title = {Identification of product definition patterns in mass customization using a learning-based hybrid approach},
	volume = {38},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-51749112495&doi=10.1007%2fs00170-007-1152-3&partnerID=40&md5=68e50c51d19cb4a5ac0427b5798abca9},
	doi = {10.1007/s00170-007-1152-3},
	abstract = {Mass customization, which aims at satisfying individual customer needs with near mass production efficiency, has become a major trend in industry. Adopting the mass customization paradigm, customer preferences have a significant impact on the product design process. Thus, it is important for companies to make proper decisions in translating the voice of customers to product specifications. To facilitate this process, a learning-based hybrid method named KBANN-DT is proposed, which combines knowledge-based artificial neural network (KBANN) and CART decision tree (DT). In this method, the KBANN algorithm is applied to modeling the relationship between customer needs and product specifications. With prior domain theory, KBANN can provide a high generalization performance even if the data set is small. Based on the trained KBANN network, the CART DT algorithm is employed to extract rules from it. To illustrate the effectiveness of the proposed method, a case study in an elevator company is reported. The results show that the proposed method can be a promising tool for product definition. © 2007 Springer-Verlag London Limited.},
	number = {11-12},
	journal = {International Journal of Advanced Manufacturing Technology},
	author = {Yu, L. and Wang, L. and Yu, J.},
	year = {2008},
	keywords = {Neural networks, Decision making, Product design, Decision tree, Decision trees, Process engineering, Mathematical models, Computer networks, Process design, Mass customization, Product definition, Sales, Specifications, Customer needs, Functional requirements, Knowledge based systems, Boolean functions, Decision theory, abstract ok, Knowledge-based artificial neural network},
	pages = {1061--1074},
}

@article{zhao_data_2010,
	title = {Data mining application on crash simulation data of occupant restraint system},
	volume = {37},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951209156&doi=10.1016%2fj.eswa.2010.02.029&partnerID=40&md5=d78e39d01b8e344b5cd6ab368212f315},
	doi = {10.1016/j.eswa.2010.02.029},
	abstract = {This article presents an application of data mining method on finite element data and crashworthiness result data of an occupant restraint system. According to the characteristics of the CAE (Computer-Aided Engineering) data, a framework for data preparation is developed based on object-oriented programming concepts. Training sets are built from data recorded in 98 crash simulations that adhere to FMVSS208, the America occupant crash protection testing standard. Relationship between design parameters and system effectiveness is implied in these data sets. Decision tree using C4.5 algorithm and attribute selection method based on attribute's estimated importance are introduced to perform data mining on the building of training sets. The result yielded by data mining endows us with a deeper insight into the interrelations between the key design parameters and the performance of the occupant restraint system in crash simulations. Finally, the learned rules are tested on the real crash simulation data sets. The result of the testing shows that these rules are proper, and can been used as a guidance for the design of the occupant restraint system. © 2010 Elsevier Ltd. All rights reserved.},
	number = {8},
	journal = {Expert Systems with Applications},
	author = {Zhao, Z. and Jin, X. and Cao, Y. and Wang, J.},
	year = {2010},
	keywords = {abstract ok, Attribute selection, C4.5 algorithm, Computer aided engineering, Crash protection, Crash simulation, Crashworthiness, Data mining, Data mining applications, Data mining methods, Data preparation, Data sets, Decision tree, Decision trees, Design, Design parameters, Finite Element, Finite element method, Key design parameters, Mining, Object oriented programming, Occupant restraint system, System effectiveness, Training sets},
	pages = {5788--5794},
}

@article{rawson_learning_2009,
	title = {Learning design rules with explicit termination conditions to enable efficient automated design},
	volume = {131},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955221162&doi=10.1115%2f1.3066681&partnerID=40&md5=ca21d45fd6d693d478a69bdcfd188dc7},
	doi = {10.1115/1.3066681},
	abstract = {We present a two-step technique for learning reusable design procedures from observations of a designer in action. This technique is intended for the domain of parametric design problems in which the designer iteratively adjusts the parameters of a design so as to satisfy the design requirements. In the first step of the two-step learning process, decision tree learning is used to infer rules that predict which design parameter the designer is likely to change for any particular state of an evolving design. In the second step, decision tree learning is again used, but this time to learn explicit termination conditions for the rules learned in the first step. The termination conditions are used to predict how large of a parameter change should be made when a rule is applied. The learned rules and termination conditions can be used to automatically solve new design problems with a minimum of human intervention. Experiments with this technique suggest that it can reproduce the decision making process observed from the designer, and it is considerably more efficient than the previous technique, which was incapable of learning explicit rule termination conditions. In particular, the rule termination conditions allow the new program to automatically solve design problems with far fewer iterations than previously required. Copyright © 2009 by ASME.},
	number = {3},
	journal = {Journal of Mechanical Design},
	author = {Rawson, K. and Stahovich, T.F.},
	year = {2009},
	keywords = {abstract ok, Automated design, Computer aided design, Decision tree learning, Decision trees, Design problems, Design procedure, Design rules, Iterative methods, Learning designs, Problem solving, Reusable design, Rule termination, Termination condition, Two-step technique},
	pages = {0310111--03101111},
}

@inproceedings{xie_analysis_2010,
	title = {The analysis of customers' satisfaction degree based on decision tree model},
	volume = {6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649234182&doi=10.1109%2fFSKD.2010.5569280&partnerID=40&md5=33b1c7cae661849cc7078c552685640c},
	doi = {10.1109/FSKD.2010.5569280},
	abstract = {Customers are resources of the enterprises' profits, Customer satisfaction degree is defined as a measure of how a firm's product or service performs compared to customer's expectations. With the market developing quickly, how to improve the customers' satisfaction degree has become the main task and object for one company. It has been a subject of research due to its importance for measuring marketing and business performance. A lot of models have been developed for its measurement. In this paper, a decision tree model is used to analyze the main factors that affect Customers' satisfaction degree. Data mining has made data processing into a more advanced stage, which is playing an important role in the science research and economic fields. The decision tree as a classification method has the advantage of processing large data quickly and accurately. We use ID3 algorithm, one of the algorithms of decision tree analysis, to analyze these key factors and resolve some important questions. Data obtained from a technology-supported company were used. Finally, we conclude that if one company wants to improve its Customers' Satisfaction degree, managers should try their best to improve the level of technology and the employees' professional skills, innovate their products continuously to satisfy more customers' needs. ©2010 IEEE.},
	author = {Xie, M.-P. and Zhao, W.-Y.},
	year = {2010},
	keywords = {Data mining, Customer satisfaction, Algorithms, Decision tree, Decision trees, Fuzzy sets, Data processing, Business performance, Industry, Profitability, Sales, Decision tree models, Classification methods, Professional skills, Large data, Industrial research, Science research, Key factors, Main tasks, abstract ok, Decision tree analysis, Customer's expectation, Customers' satisfaction degree, Economic fields, ID3 algorithm},
	pages = {2928--2931},
}
